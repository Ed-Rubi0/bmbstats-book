@Book{pageModelThinkerWhat2018,
  title = {The {{Model Thinker}}: {{What You Need}} to {{Know}} to {{Make Data Work}} for {{You}}},
  shorttitle = {The {{Model Thinker}}},
  abstract = {How anyone can become a data ninja From the stock market to genomics laboratories, census figures to marketing email blasts, we are awash with data. But as anyone who has ever opened up a spreadsheet packed with seemingly infinite lines of data knows, numbers aren't enough: we need to know how to make those numbers talk. In The Model Thinker, social scientist Scott E. Page shows us the mathematical, statistical, and computational models--from linear regression to random walks and far beyond--that can turn anyone into a genius. At the core of the book is Page's {"}many-model paradigm,{"} which shows the reader how to apply multiple models to organize the data, leading to wiser choices, more accurate predictions, and more robust designs. The Model Thinker provides a toolkit for business people, students, scientists, pollsters, and bloggers to make them better, clearer thinkers, able to leverage data and information to their advantage.},
  language = {English},
  publisher = {{Basic Books}},
  author = {Scott E. Page},
  month = {nov},
  year = {2018},
}

@Book{weinbergSuperThinkingBig2019,
  address = {{New York}},
  title = {Super Thinking: The Big Book of Mental Models},
  isbn = {978-0-525-53359-7 978-0-525-54281-0},
  lccn = {BF441},
  shorttitle = {Super Thinking},
  publisher = {{Portfolio/Penguin}},
  author = {Gabriel Weinberg and Lauren McCann},
  year = {2019},
  keywords = {Cognition,Reasoning,Thought and thinking},
}
@Book{pearlBookWhyNew2018,
  address = {{New York}},
  edition = {1 edition},
  title = {The {{Book}} of {{Why}}: {{The New Science}} of {{Cause}} and {{Effect}}},
  isbn = {978-0-465-09760-9},
  shorttitle = {The {{Book}} of {{Why}}},
  abstract = {A Turing Award-winning computer scientist and statistician shows how understanding causality has revolutionized science and will revolutionize artificial intelligence{"}Correlation is not causation.{"} This mantra, chanted by scientists for more than a century, has led to a virtual prohibition on causal talk. Today, that taboo is dead. The causal revolution, instigated by Judea Pearl and his colleagues, has cut through a century of confusion and established causality--the study of cause and effect--on a firm scientific basis. His work explains how we can know easy things, like whether it was rain or a sprinkler that made a sidewalk wet; and how to answer hard questions, like whether a drug cured an illness. Pearl's work enables us to know not just whether one thing causes another: it lets us explore the world that is and the worlds that could have been. It shows us the essence of human thought and key to artificial intelligence. Anyone who wants to understand either needs The Book of Why.},
  language = {English},
  publisher = {{Basic Books}},
  author = {Judea Pearl and Dana Mackenzie},
  month = {may},
  year = {2018},
}

@Book{mcelreathStatisticalRethinkingBayesian2015,
  address = {{Boca Raton}},
  edition = {1 edition},
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  isbn = {978-1-4822-5344-3},
  shorttitle = {Statistical {{Rethinking}}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers' knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today's model-based statistics, the book pushes readers to perform step-by-step calculations that are usually automated. This unique computational approach ensures that readers understand enough of the details to make reasonable choices and interpretations in their own modeling work.  The text presents generalized linear multilevel models from a Bayesian perspective, relying on a simple logical interpretation of Bayesian probability and maximum entropy. It covers from the basics of regression to multilevel models. The author also discusses measurement error, missing data, and Gaussian process models for spatial and network autocorrelation.  By using complete R code examples throughout, this book provides a practical foundation for performing statistical inference. Designed for both PhD students and seasoned professionals in the natural and social sciences, it prepares them for more advanced or specialized statistical modeling.  Web ResourceThe book is accompanied by an R package (rethinking) that is available on the author's website and GitHub. The two core functions (map and map2stan) of this package allow a variety of statistical models to be constructed from standard model formulas.},
  language = {English},
  publisher = {{Chapman and Hall/CRC}},
  author = {Richard McElreath},
  month = {dec},
  year = {2015},
}

@Article{hernanSecondChanceGet2019,
  title = {A {{Second Chance}} to {{Get Causal Inference Right}}: {{A Classification}} of {{Data Science Tasks}}},
  volume = {32},
  issn = {0933-2480, 1867-2280},
  shorttitle = {A {{Second Chance}} to {{Get Causal Inference Right}}},
  language = {en},
  number = {1},
  journal = {CHANCE},
  doi = {10.1080/09332480.2019.1579578},
  author = {Miguel A. Hernán and John Hsu and Brian Healy},
  month = {jan},
  year = {2019},
  pages = {42-49},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/DX7WM7LA/Hernán et al. - 2019 - A Second Chance to Get Causal Inference Right A C.pdf},
}

@Article{langGettingNullStatistical2017,
  title = {Getting beyond the {{Null}}: {{Statistical Modeling}} as an {{Alternative Framework}} for {{Inference}} in {{Developmental Science}}},
  volume = {14},
  issn = {1542-7609, 1542-7617},
  shorttitle = {Getting beyond the {{Null}}},
  language = {en},
  number = {4},
  journal = {Research in Human Development},
  doi = {10.1080/15427609.2017.1371567},
  author = {Kyle M. Lang and Shauna J. Sweet and Elizabeth M. Grandfield},
  month = {oct},
  year = {2017},
  pages = {287-304},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/FNJELMDR/Lang et al. - 2017 - Getting beyond the Null Statistical Modeling as a.pdf},
}
@Book{mcelreathStatisticalRethinkingBayesian2015,
  address = {{Boca Raton}},
  edition = {1 edition},
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{Stan}}},
  isbn = {978-1-4822-5344-3},
  shorttitle = {Statistical {{Rethinking}}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds readers' knowledge of and confidence in statistical modeling. Reflecting the need for even minor programming in today's model-based statistics, the book pushes readers to perform step-by-step calculations that are usually automated. This unique computational approach ensures that readers understand enough of the details to make reasonable choices and interpretations in their own modeling work.  The text presents generalized linear multilevel models from a Bayesian perspective, relying on a simple logical interpretation of Bayesian probability and maximum entropy. It covers from the basics of regression to multilevel models. The author also discusses measurement error, missing data, and Gaussian process models for spatial and network autocorrelation.  By using complete R code examples throughout, this book provides a practical foundation for performing statistical inference. Designed for both PhD students and seasoned professionals in the natural and social sciences, it prepares them for more advanced or specialized statistical modeling.  Web ResourceThe book is accompanied by an R package (rethinking) that is available on the author's website and GitHub. The two core functions (map and map2stan) of this package allow a variety of statistical models to be constructed from standard model formulas.},
  language = {English},
  publisher = {{Chapman and Hall/CRC}},
  author = {Richard McElreath},
  month = {dec},
  year = {2015},
}
@Book{gigerenzerHeuristicsFoundationsAdaptive2015,
  edition = {Reprint edition},
  title = {Heuristics: {{The Foundations}} of {{Adaptive Behavior}}},
  isbn = {978-0-19-049462-9},
  shorttitle = {Heuristics},
  abstract = {How do people make decisions when time is limited, information unreliable, and the future uncertain? Based on the work of Nobel laureate Herbert Simon and with the help of colleagues around the world, the Adaptive Behavior and Cognition (ABC) Group at the Max Planck Institute for Human Development in Berlin has developed a research program on simple heuristics, also known as fast and frugal heuristics. In the social sciences, heuristics have been believed to be generally inferior to complex methods for inference, or even irrational. Although this may be true in {"}small worlds{"} where everything is known for certain, we show that in the actual world in which we live, full of uncertainties and surprises, heuristics are indispensable and often more accurate than complex methods. Contrary to a deeply entrenched belief, complex problems do not necessitate complex computations. Less can be more. Simple heuristics exploit the information structure of the environment, and thus embody ecological rather than logical rationality. Simon (1999) applauded this new program as a {"}revolution in cognitive science, striking a great blow for sanity in the approach to human rationality.{"}By providing a fresh look at how the mind works as well as the nature of rationality, the simple heuristics program has stimulated a large body of research, led to fascinating applications in diverse fields from law to medicine to business to sports, and instigated controversial debates in psychology, philosophy, and economics. In a single volume, the present reader compiles key articles that have been published in journals across many disciplines. These articles present theory, real-world applications, and a sample of the large number of existing experimental studies that provide evidence for people's adaptive use of heuristics.},
  language = {English},
  publisher = {{Oxford University Press}},
  author = {Gerd Gigerenzer and Ralph Hertwig and Thorsten Pachur},
  month = {dec},
  year = {2015},
}

@Book{savageFoundationsStatistics1972,
  address = {{New York}},
  edition = {2nd Revised ed. edition},
  title = {The {{Foundations}} of {{Statistics}}},
  isbn = {978-0-486-62349-8},
  abstract = {With the 1954 publication of his Foundations of Statistics, in which he proposed a basis that takes into account not only strictly objective and repetitive events, but also vagueness and interpersonal differences, Leonard J. Savage opened the greatest controversy in modern statistical thought. His theory of the foundations, connected with the personalistic interpretation of probability, challenged the then dominant frequentist school. In the first seven chapters of his book, Professor Savage is concerned with the foundations at a relatively deep level. To explain and defend his theory of the behavior of a highly idealized person faced with uncertainty, he considers decision making, the sure-thing principle, qualitative and quantitative personal probability, the approach to certainty through experience, symmetric sequences of events, critical comments on personal probability, utility, observations as they affect the decision, and partition problems. In chapters eight through seventeen he discusses statistics proper \textemdash{} the actual devices of the discipline \textemdash{} from the personalistic view. He concentrates on minimax problems and on the theories of estimation and testing. Exercises are included throughout to reinforce and supplement the text. The mathematical techniques used are quite elementary, some calculus and elementary probability theory being presupposed. Understanding of all the material calls for some mathematical maturity on the part of the reader. Professor Savage had reevaluated his position somewhat during the decade and a half since the work was first published. While reaffirming the material in the first seven chapters, he had reconsidered the appropriateness of many frequentistic applications. To explain these recent developments, he added a new preface, new footnotes, and a supplementary 180-item, annotated bibliography. Because of Professor Savage's death, the revisions that he made for this edition are his final analysis of the situation.As he says on page one, {"}the foundations are the most controversial parts of many, if not all, sciences.{"} In statistics, the foundation of probability is {"}as controversial a subject as one could name.{"} In 1954, the controversy was very great, and although it has quieted since, the problem has yet to be resolved. A new generation of readers who have missed Savage's analysis have here an opportunity to study firsthand what his important foundation of statistics \textemdash{} personal probability \textemdash{} is, and what it means to statistical thought.},
  language = {English},
  publisher = {{Dover Publications}},
  author = {Leonard J. Savage},
  month = {jun},
  year = {1972},
}

@Book{gigerenzerRiskSavvyHow2015,
  edition = {Reprint edition},
  title = {Risk {{Savvy}}: {{How}} to {{Make Good Decisions}}},
  isbn = {978-0-14-312710-9},
  shorttitle = {Risk {{Savvy}}},
  abstract = {A new eye-opener on how we can make better decisions\textemdash{}by the author of Gut FeelingsIn this age of big data we often trust that expert analysis\textemdash{}whether it's about next year's stock market or a person's risk of getting cancer\textemdash{}is accurate. But, as risk expert Gerd Gigerenzer reveals in his latest book, Risk Savvy, most of us, including doctors, lawyers, and financial advisors, often misunderstand statistics, leaving us misinformed and vulnerable to exploitation.Yet there's hope. In Risk Savvy, Gigerenzer gives us an essential guide to the science of good decision making, showing how ordinary people can make better decisions for their money, their health, and their families. Here, Gigerenzer delivers the surprising conclusion that the best results often come from considering less information and listening to your gut.},
  language = {English},
  publisher = {{Penguin Books}},
  author = {Gerd Gigerenzer},
  month = {mar},
  year = {2015},
}

@InCollection{Gigerenzer:2004tw,
  title = {Striking a {{Blow}} for {{Sanity}} in {{Theories}} of {{Rationality}}},
  booktitle = {Models of a {{Man}}},
  publisher = {{MIT Press}},
  author = {Gerd Gigerenzer},
  year = {2004},
  pages = {1-12},
}

@Article{Gigerenzer:2008wl,
  title = {Why {{Heuristics Work}}},
  volume = {3},
  number = {1},
  journal = {Perspectives on Psychological Science},
  author = {Gerd Gigerenzer},
  month = {jan},
  year = {2008},
  pages = {1-10},
}

@Article{Volz:2012cq,
  title = {Cognitive Processes in Decisions under Risk Are Not the Same as in Decisions under Uncertainty},
  volume = {6},
  number = {105},
  journal = {Frontiers in neuroscience},
  doi = {10.3389/fnins.2012.00105},
  author = {Kirsten G Volz and Gerd Gigerenzer},
  month = {jul},
  year = {2012},
}

@InCollection{Anonymous:Et7RsJq1,
  address = {{Hoboken, NJ, USA}},
  title = {Heuristics: {{Tools}} for an {{Uncertain World}}},
  booktitle = {Emerging {{Trends}} in the {{Social}} and {{Behavioral Sciences}}},
  publisher = {{John Wiley \& Sons}},
  author = {Hansjorg Neth and Gerd Gigerenzer},
  editor = {Robert A Scott and Stephan M Kosslyn},
  month = {may},
  year = {2015},
  pages = {1-18},
}

@Article{Mousavi:2014hg,
  title = {Risk, Uncertainty, and Heuristics},
  volume = {67},
  number = {8},
  journal = {Journal of Business Research},
  author = {Shabnam Mousavi and Gerd Gigerenzer},
  month = {aug},
  year = {2014},
  pages = {1671-1678},
}

@Article{Gigerenzer:2011hd,
  title = {Heuristic Decision Making.},
  volume = {62},
  number = {1},
  journal = {Annual review of psychology},
  author = {Gerd Gigerenzer and Wolfgang Gaissmaier},
  year = {2011},
  pages = {451-482},
}

@Book{binmoreRationalDecisions2011,
  address = {{Princeton, NJ}},
  edition = {Fourth Impression edition},
  title = {Rational {{Decisions}}},
  isbn = {978-0-691-14989-9},
  abstract = {It is widely held that Bayesian decision theory is the final word on how a rational person should make decisions. However, Leonard Savage--the inventor of Bayesian decision theory--argued that it would be ridiculous to use his theory outside the kind of small world in which it is always possible to {"}look before you leap.{"} If taken seriously, this view makes Bayesian decision theory inappropriate for the large worlds of scientific discovery and macroeconomic enterprise. When is it correct to use Bayesian decision theory--and when does it need to be modified? Using a minimum of mathematics, Rational Decisions clearly explains the foundations of Bayesian decision theory and shows why Savage restricted the theory's application to small worlds. The book is a wide-ranging exploration of standard theories of choice and belief under risk and uncertainty. Ken Binmore discusses the various philosophical attitudes related to the nature of probability and offers resolutions to paradoxes believed to hinder further progress. In arguing that the Bayesian approach to knowledge is inadequate in a large world, Binmore proposes an extension to Bayesian decision theory--allowing the idea of a mixed strategy in game theory to be expanded to a larger set of what Binmore refers to as {"}muddled{"} strategies. Written by one of the world's leading game theorists, Rational Decisions is the touchstone for anyone needing a concise, accessible, and expert view on Bayesian decision making.},
  language = {English},
  publisher = {{Princeton University Press}},
  author = {Ken Binmore},
  month = {mar},
  year = {2011},
}
@Book{gigerenzerHeuristicsFoundationsAdaptive2015,
  edition = {Reprint edition},
  title = {Heuristics: {{The Foundations}} of {{Adaptive Behavior}}},
  isbn = {978-0-19-049462-9},
  shorttitle = {Heuristics},
  abstract = {How do people make decisions when time is limited, information unreliable, and the future uncertain? Based on the work of Nobel laureate Herbert Simon and with the help of colleagues around the world, the Adaptive Behavior and Cognition (ABC) Group at the Max Planck Institute for Human Development in Berlin has developed a research program on simple heuristics, also known as fast and frugal heuristics. In the social sciences, heuristics have been believed to be generally inferior to complex methods for inference, or even irrational. Although this may be true in {"}small worlds{"} where everything is known for certain, we show that in the actual world in which we live, full of uncertainties and surprises, heuristics are indispensable and often more accurate than complex methods. Contrary to a deeply entrenched belief, complex problems do not necessitate complex computations. Less can be more. Simple heuristics exploit the information structure of the environment, and thus embody ecological rather than logical rationality. Simon (1999) applauded this new program as a {"}revolution in cognitive science, striking a great blow for sanity in the approach to human rationality.{"}By providing a fresh look at how the mind works as well as the nature of rationality, the simple heuristics program has stimulated a large body of research, led to fascinating applications in diverse fields from law to medicine to business to sports, and instigated controversial debates in psychology, philosophy, and economics. In a single volume, the present reader compiles key articles that have been published in journals across many disciplines. These articles present theory, real-world applications, and a sample of the large number of existing experimental studies that provide evidence for people's adaptive use of heuristics.},
  language = {English},
  publisher = {{Oxford University Press}},
  author = {Gerd Gigerenzer and Ralph Hertwig and Thorsten Pachur},
  month = {dec},
  year = {2015},
}

@Book{savageFoundationsStatistics1972,
  address = {{New York}},
  edition = {2nd Revised ed. edition},
  title = {The {{Foundations}} of {{Statistics}}},
  isbn = {978-0-486-62349-8},
  abstract = {With the 1954 publication of his Foundations of Statistics, in which he proposed a basis that takes into account not only strictly objective and repetitive events, but also vagueness and interpersonal differences, Leonard J. Savage opened the greatest controversy in modern statistical thought. His theory of the foundations, connected with the personalistic interpretation of probability, challenged the then dominant frequentist school. In the first seven chapters of his book, Professor Savage is concerned with the foundations at a relatively deep level. To explain and defend his theory of the behavior of a highly idealized person faced with uncertainty, he considers decision making, the sure-thing principle, qualitative and quantitative personal probability, the approach to certainty through experience, symmetric sequences of events, critical comments on personal probability, utility, observations as they affect the decision, and partition problems. In chapters eight through seventeen he discusses statistics proper \textemdash{} the actual devices of the discipline \textemdash{} from the personalistic view. He concentrates on minimax problems and on the theories of estimation and testing. Exercises are included throughout to reinforce and supplement the text. The mathematical techniques used are quite elementary, some calculus and elementary probability theory being presupposed. Understanding of all the material calls for some mathematical maturity on the part of the reader. Professor Savage had reevaluated his position somewhat during the decade and a half since the work was first published. While reaffirming the material in the first seven chapters, he had reconsidered the appropriateness of many frequentistic applications. To explain these recent developments, he added a new preface, new footnotes, and a supplementary 180-item, annotated bibliography. Because of Professor Savage's death, the revisions that he made for this edition are his final analysis of the situation.As he says on page one, {"}the foundations are the most controversial parts of many, if not all, sciences.{"} In statistics, the foundation of probability is {"}as controversial a subject as one could name.{"} In 1954, the controversy was very great, and although it has quieted since, the problem has yet to be resolved. A new generation of readers who have missed Savage's analysis have here an opportunity to study firsthand what his important foundation of statistics \textemdash{} personal probability \textemdash{} is, and what it means to statistical thought.},
  language = {English},
  publisher = {{Dover Publications}},
  author = {Leonard J. Savage},
  month = {jun},
  year = {1972},
}

@Book{binmoreRationalDecisions2011,
  address = {{Princeton, NJ}},
  edition = {Fourth Impression edition},
  title = {Rational {{Decisions}}},
  isbn = {978-0-691-14989-9},
  abstract = {It is widely held that Bayesian decision theory is the final word on how a rational person should make decisions. However, Leonard Savage--the inventor of Bayesian decision theory--argued that it would be ridiculous to use his theory outside the kind of small world in which it is always possible to {"}look before you leap.{"} If taken seriously, this view makes Bayesian decision theory inappropriate for the large worlds of scientific discovery and macroeconomic enterprise. When is it correct to use Bayesian decision theory--and when does it need to be modified? Using a minimum of mathematics, Rational Decisions clearly explains the foundations of Bayesian decision theory and shows why Savage restricted the theory's application to small worlds. The book is a wide-ranging exploration of standard theories of choice and belief under risk and uncertainty. Ken Binmore discusses the various philosophical attitudes related to the nature of probability and offers resolutions to paradoxes believed to hinder further progress. In arguing that the Bayesian approach to knowledge is inadequate in a large world, Binmore proposes an extension to Bayesian decision theory--allowing the idea of a mixed strategy in game theory to be expanded to a larger set of what Binmore refers to as {"}muddled{"} strategies. Written by one of the world's leading game theorists, Rational Decisions is the touchstone for anyone needing a concise, accessible, and expert view on Bayesian decision making.},
  language = {English},
  publisher = {{Princeton University Press}},
  author = {Ken Binmore},
  month = {mar},
  year = {2011},
}
@Article{hernanSecondChanceGet2019,
  title = {A {{Second Chance}} to {{Get Causal Inference Right}}: {{A Classification}} of {{Data Science Tasks}}},
  volume = {32},
  issn = {0933-2480, 1867-2280},
  shorttitle = {A {{Second Chance}} to {{Get Causal Inference Right}}},
  language = {en},
  number = {1},
  journal = {CHANCE},
  doi = {10.1080/09332480.2019.1579578},
  author = {Miguel A. Hernán and John Hsu and Brian Healy},
  month = {jan},
  year = {2019},
  pages = {42-49},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/DX7WM7LA/Hernán et al. - 2019 - A Second Chance to Get Causal Inference Right A C.pdf},
}
@Article{amrheinInferentialStatisticsDescriptive2019,
  title = {Inferential {{Statistics}} as {{Descriptive Statistics}}: {{There Is No Replication Crisis}} If {{We Don}}'t {{Expect Replication}}},
  volume = {73},
  issn = {0003-1305, 1537-2731},
  shorttitle = {Inferential {{Statistics}} as {{Descriptive Statistics}}},
  language = {en},
  number = {sup1},
  journal = {The American Statistician},
  doi = {10.1080/00031305.2018.1543137},
  author = {Valentin Amrhein and David Trafimow and Sander Greenland},
  month = {mar},
  year = {2019},
  pages = {262-270},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/A96RTC8C/Amrhein et al. - 2019 - Inferential Statistics as Descriptive Statistics .pdf},
}
@Article{gelmanSubjectiveObjectiveStatistics2017,
  title = {Beyond Subjective and Objective in Statistics},
  volume = {180},
  issn = {09641998},
  language = {en},
  number = {4},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  doi = {10.1111/rssa.12276},
  author = {Andrew Gelman and Christian Hennig},
  month = {oct},
  year = {2017},
  pages = {967-1033},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CV34AELR/Gelman and Hennig - 2017 - Beyond subjective and objective in statistics.pdf},
}
@Book{mitchellUnsimpleTruthsScience2012,
  address = {{Chicago, Mich.}},
  edition = {paperback ed},
  title = {Unsimple Truths: Science, Complexity, and Policy},
  isbn = {978-0-226-00662-8},
  shorttitle = {Unsimple Truths},
  abstract = {The author argues that the long-standing scientific and philosophical deference to reductive explanations founded on simple universal laws, linear causal models, and predict-and-act strategies fails to accommodate the kinds of knowledge that many contemporary sciences are providing about the world},
  language = {eng},
  publisher = {{The Univ. of Chicago Press}},
  author = {Sandra Mitchell},
  year = {2012},
  note = {OCLC: 935804349},
}

@Article{mitchellIntegrativePluralism2002,
  title = {Integrative {{Pluralism}}},
  volume = {17},
  issn = {0169-3867, 1572-8404},
  language = {en},
  number = {1},
  journal = {Biology \& Philosophy},
  doi = {10.1023/A:1012990030867},
  author = {Sandra D. Mitchell},
  month = {jan},
  year = {2002},
  pages = {55-70},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/TKJZFXRS/Mitchell - 2002 - Integrative Pluralism.pdf},
}
@Article{mitchellIntegrativePluralism2002,
  title = {Integrative {{Pluralism}}},
  volume = {17},
  issn = {0169-3867, 1572-8404},
  language = {en},
  number = {1},
  journal = {Biology \& Philosophy},
  doi = {10.1023/A:1012990030867},
  author = {Sandra D. Mitchell},
  month = {jan},
  year = {2002},
  pages = {55-70},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/TKJZFXRS/Mitchell - 2002 - Integrative Pluralism.pdf},
}

@Book{wickhamTidyverseEasilyInstall2017,
  title = {Tidyverse: {{Easily Install}} and {{Load}} the '{{Tidyverse}}'},
  author = {Hadley Wickham},
  year = {2017},
}

@Book{wilkeCowplotStreamlinedPlot2019,
  title = {Cowplot: {{Streamlined Plot Theme}} and {{Plot Annotations}} for 'Ggplot2'},
  author = {Claus O. Wilke},
  year = {2019},
}

@Book{wickhamTidyverseEasilyInstall2017,
  title = {Tidyverse: {{Easily Install}} and {{Load}} the '{{Tidyverse}}'},
  author = {Hadley Wickham},
  year = {2017},
}
@Book{xiaoGgsciScientificJournal2018,
  title = {Ggsci: {{Scientific Journal}} and {{Sci}}-{{Fi Themed Color Palettes}} for 'Ggplot2'},
  author = {Nan Xiao},
  year = {2018},
}
@Book{xieBookdownAuthoringBooks2016,
  address = {{Boca Raton, Florida}},
  title = {Bookdown: {{Authoring Books}} and {{Technical Documents}} with {{R Markdown}}},
  publisher = {{Chapman and Hall/CRC}},
  author = {Yihui Xie},
  year = {2016},
}
@Book{revellePsychProceduresPsychological2018,
  address = {{Evanston, Illinois}},
  title = {Psych: {{Procedures}} for {{Psychological}}, {{Psychometric}}, and {{Personality Research}}},
  publisher = {{Northwestern University}},
  author = {William Revelle},
  year = {2018},
}
@Book{darocziPanderPandocWriter2018,
  title = {Pander: {{An R}} '{{Pandoc}}' {{Writer}}},
  author = {Gergely Dar{\a'o}czi and Roman Tsegelskyi},
  year = {2018},
}
@Book{heinzenArsenalArsenalFunctions2018,
  title = {Arsenal: {{An Arsenal}} of '{{R}}' {{Functions}} for {{Large}}-{{Scale Statistical Summaries}}},
  author = {Ethan Heinzen and Jason Sinnwell and Elizabeth Atkinson and Tina Gunderson and Gregory Dougherty},
  year = {2018},
}
@Book{xieKnitrGeneralPurposePackage2018,
  title = {Knitr: {{A General}}-{{Purpose Package}} for {{Dynamic Report Generation}} in {{R}}},
  author = {Yihui Xie},
  year = {2018},
}

@Book{xieDynamicDocumentsKnitr2015,
  address = {{Boca Raton, Florida}},
  edition = {2nd},
  title = {Dynamic {{Documents}} with {{R}} and Knitr},
  publisher = {{Chapman and Hall/CRC}},
  author = {Yihui Xie},
  year = {2015},
}

@InCollection{xieKnitrComprehensiveTool2014,
  title = {Knitr: {{A Comprehensive Tool}} for {{Reproducible Research}} in {{R}}},
  booktitle = {Implementing {{Reproducible Computational Research}}},
  publisher = {{Chapman and Hall/CRC}},
  author = {Yihui Xie},
  editor = {Victoria Stodden and Friedrich Leisch and Roger D. Peng},
  year = {2014},
}
@Book{zhuKableExtraConstructComplex2019,
  title = {{{kableExtra}}: {{Construct Complex Table}} with 'kable' and {{Pipe Syntax}}},
  author = {Hao Zhu},
  year = {2019},
}
@Article{wilcoxGuideRobustStatistical2017,
  title = {A Guide to Robust Statistical Methods in Neuroscience},
  abstract = {There is a vast array of new and improved methods for comparing groups and studying associations that offer the potential for substantially increasing power, providing improved control over the probability of a Type I error, and yielding a deeper and more nuanced understanding of neuroscience data. These new techniques effectively deal with four insights into when and why conventional methods can be unsatisfactory. But for the non-statistician, the vast array of new and improved techniques for comparing groups and studying associations can seem daunting, simply because there are so many new methods that are now available. The paper briefly reviews when and why conventional methods can have relatively low power and yield misleading results. The main goal is to suggest some general guidelines regarding when, how and why certain modern techniques might be used.},
  language = {en},
  journal = {bioRxiv},
  doi = {10.1101/151811},
  author = {Rand R. Wilcox and Guillaume A. Rousselet},
  month = {jun},
  year = {2017},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CJ95LP5X/Wilcox and Rousselet - 2017 - A guide to robust statistical methods in neuroscie.pdf},
}
@Article{wilcoxDataAnalysesWhen2018,
  title = {Data {{Analyses When Sample Sizes Are Small}}: {{Modern Advances}} for {{Dealing With Outliers}}, {{Skewed Distributions}}, and {{Heteroscedasticity}}},
  volume = {34},
  issn = {1065-8483, 1543-2688},
  shorttitle = {Data {{Analyses When Sample Sizes Are Small}}},
  abstract = {The paper reviews advances and insights relevant to comparing groups when the sample sizes are small. There are conditions under which conventional, routinely used techniques are satisfactory. But major insights regarding outliers, skewed distributions, and unequal variances (heteroscedasticity) make it clear that under general conditions they provide poor control over the type I error probability and can have relatively poor power. In practical terms, important differences among groups can be missed and poorly characterized. Many new and improved methods have been derived that are aimed at dealing with the shortcomings of classic methods. To provide a conceptual basis for understanding the practical importance of modern methods, the paper reviews some modern insights related to why methods based on means can perform poorly. Then some strategies for dealing with nonnormal distributions and unequal variances are described. For brevity, the focus is on comparing 2 independent groups or 2 dependent groups based on the usual difference scores. The paper concludes with comments on issues to consider when choosing from among the methods reviewed in the paper.},
  language = {en},
  number = {4},
  journal = {Journal of Applied Biomechanics},
  doi = {10.1123/jab.2017-0269},
  author = {Rand Wilcox and Travis J. Peterson and Jill L. McNitt-Gray},
  month = {aug},
  year = {2018},
  pages = {258-261},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/SGE4X77R/Wilcox et al. - 2018 - Data Analyses When Sample Sizes Are Small Modern .pdf},
}

@Article{rousseletDifferencesMeansRobust2017,
  title = {Beyond Differences in Means: Robust Graphical Methods to Compare Two Groups in Neuroscience},
  volume = {46},
  issn = {0953816X},
  shorttitle = {Beyond Differences in Means},
  abstract = {If many changes are necessary to improve the quality of neuroscience research, one relatively simple step could have great pay-offs: to promote the adoption of detailed graphical methods, combined with robust inferential statistics. Here we illustrate how such methods can lead to a much more detailed understanding of group differences than bar graphs and t-tests on means. To complement the neuroscientist's toolbox, we present two powerful tools that can help us understand how groups of observations differ: the shift function and the difference asymmetry function. These tools can be combined with detailed visualisations to provide This article has been accepted for publication and undergone full peer review but has not been through the copyediting, typesetting, pagination and proofreading process, which may lead to differences between this version and the Version of Record. Please cite this article as doi: 10.1111/ejn.13610 This article is protected by copyright. All rights reserved.},
  language = {en},
  number = {2},
  journal = {European Journal of Neuroscience},
  doi = {10.1111/ejn.13610},
  author = {Guillaume A. Rousselet and Cyril R. Pernet and Rand R. Wilcox},
  month = {jul},
  year = {2017},
  pages = {1738-1748},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/KF4ZVEQK/Rousselet et al. - 2017 - Beyond differences in means robust graphical meth.pdf},
}

@Book{wilcoxIntroductionRobustEstimation2016,
  address = {{Waltham, MA}},
  edition = {4th edition},
  title = {Introduction to Robust Estimation and Hypothesis Testing},
  isbn = {978-0-12-804733-0},
  publisher = {{Elsevier}},
  author = {Rand R. Wilcox},
  year = {2016},
}@Book{wilkeGgridgesRidgelinePlots2018,
  title = {Ggridges: {{Ridgeline Plots}} in 'Ggplot2'},
  author = {Claus O. Wilke},
  year = {2018},
}
@Article{allenRaincloudPlotsMultiplatform2019,
  title = {Raincloud Plots: A Multi-Platform Tool for Robust Data Visualization},
  volume = {4},
  issn = {2398-502X},
  shorttitle = {Raincloud Plots},
  language = {en},
  journal = {Wellcome Open Research},
  doi = {10.12688/wellcomeopenres.15191.1},
  author = {Micah Allen and Davide Poggiali and Kirstie Whitaker and Tom Rhys Marshall and Rogier A. Kievit},
  month = {apr},
  year = {2019},
  pages = {63},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/C88ZC4F2/Allen et al. - 2019 - Raincloud plots a multi-platform tool for robust .pdf},
}

@Misc{allenRaincloudplotsTutorialsCodebase2018,
  title = {Raincloudplots {{Tutorials And Codebase}}},
  abstract = {This is the first release of the RainCloudPlots codebase and tutorials. It accompanies the PeerJ preprint {$<$}strong{$>$}Raincloud plots: a multi-platform tool for robust data visualization{$<$}/strong{$>$}.

Allen M, Poggiali D, Whitaker K, Marshall TR, Kievit R. (2018) Raincloud plots: a multi-platform tool for robust data visualization. PeerJ Preprints 6:e27137v1 https://doi.org/10.7287/peerj.preprints.27137v1},
  publisher = {{Zenodo}},
  author = {Micah Allen and Davide Poggiali and Kirstie Whitaker and Tom Rhys Marshall and Rogier Kievit},
  month = {aug},
  year = {2018},
  doi = {10.5281/zenodo.1402959},
}
@Book{cohenStatisticalPowerAnalysis1988,
  address = {{Hillsdale, N.J}},
  edition = {2nd ed},
  title = {Statistical Power Analysis for the Behavioral Sciences},
  isbn = {978-0-8058-0283-2},
  lccn = {HA29 .C66 1988},
  publisher = {{L. Erlbaum Associates}},
  author = {Jacob Cohen},
  year = {1988},
  keywords = {Probabilities,Social sciences,Statistical methods,Statistical power analysis},
}
@Article{hopkinsProgressiveStatisticsStudies2009,
  title = {Progressive {{Statistics}} for {{Studies}} in {{Sports Medicine}} and {{Exercise Science}}:},
  volume = {41},
  issn = {0195-9131},
  shorttitle = {Progressive {{Statistics}} for {{Studies}} in {{Sports Medicine}} and {{Exercise Science}}},
  abstract = {State why you studied the effect(s). \textbullet{} State the design, including any randomizing and blinding. \textbullet{} Characterize the subjects who contributed to the estimate of the effect(s) (final sample size, sex, skill, status\ldots{}). \textbullet{} Ensure all numbers are either in numeric or graphical form in the Results section of the manuscript. \textbullet{} Show magnitudes and confidence intervals or limits of the most important effect(s). Avoid P values. [Note 1] \textbullet{} Make a probabilistic statement about clinical, practical, or mechanistic importance of the effect(s). \textbullet{} The conclusion must not be simply a restatement of results.},
  language = {en},
  number = {1},
  journal = {Medicine \& Science in Sports \& Exercise},
  doi = {10.1249/MSS.0b013e31818cb278},
  author = {William G. Hopkins and Stephen W. Marshall and Alan M. Batterham and Juri Hanin},
  month = {jan},
  year = {2009},
  pages = {3-13},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/IIKNANP5/Hopkins et al. - 2009 - Progressive Statistics for Studies in Sports Medic.pdf},
}

@Misc{hopkinsNewViewStatistics2006,
  title = {New {{View}} of {{Statistics}}: {{Effect Magnitudes}}},
  howpublished = {https://www.sportsci.org/resource/stats/effectmag.html},
  author = {Will G Hopkins},
  month = {aug},
  year = {2006},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/ZQTA3BRW/effectmag.html},
}

@Article{hopkinsProgressiveStatisticsStudies2009,
  title = {Progressive {{Statistics}} for {{Studies}} in {{Sports Medicine}} and {{Exercise Science}}:},
  volume = {41},
  issn = {0195-9131},
  shorttitle = {Progressive {{Statistics}} for {{Studies}} in {{Sports Medicine}} and {{Exercise Science}}},
  abstract = {State why you studied the effect(s). \textbullet{} State the design, including any randomizing and blinding. \textbullet{} Characterize the subjects who contributed to the estimate of the effect(s) (final sample size, sex, skill, status\ldots{}). \textbullet{} Ensure all numbers are either in numeric or graphical form in the Results section of the manuscript. \textbullet{} Show magnitudes and confidence intervals or limits of the most important effect(s). Avoid P values. [Note 1] \textbullet{} Make a probabilistic statement about clinical, practical, or mechanistic importance of the effect(s). \textbullet{} The conclusion must not be simply a restatement of results.},
  language = {en},
  number = {1},
  journal = {Medicine \& Science in Sports \& Exercise},
  doi = {10.1249/MSS.0b013e31818cb278},
  author = {William G. Hopkins and Stephen W. Marshall and Alan M. Batterham and Juri Hanin},
  month = {jan},
  year = {2009},
  pages = {3-13},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/VUWUDGFT/Hopkins et al. - 2009 - Progressive Statistics for Studies in Sports Medic.pdf},
}
@Article{buchheit3015Intermittent2014,
  title = {The 30\textendash{}15 {{Intermittent Fitness Test Versus}} the {{Yo}}-{{Yo Intermittent Recovery Test Level}} 1: {{Relationship}} and {{Sensitivity}} to {{Training}}},
  volume = {9},
  issn = {1555-0265, 1555-0273},
  shorttitle = {The 30\textendash{}15 {{Intermittent Fitness Test Versus}} the {{Yo}}-{{Yo Intermittent Recovery Test Level}} 1},
  number = {3},
  journal = {International Journal of Sports Physiology and Performance},
  doi = {10.1123/ijspp.2012-0335},
  author = {Martin Buchheit and Alireza Rabbani},
  month = {may},
  year = {2014},
  pages = {522-524},
}
@Article{mcgrawCommonLanguageEffect1992,
  title = {A Common Language Effect Size Statistic.},
  volume = {111},
  issn = {0033-2909},
  language = {en},
  number = {2},
  journal = {Psychological Bulletin},
  doi = {10.1037/0033-2909.111.2.361},
  author = {Kenneth O. McGraw and S. P. Wong},
  year = {1992},
  pages = {361-365},
}
@Book{jamesIntroductionStatisticalLearning2017,
  address = {{New York}},
  edition = {1st ed. 2013, Corr. 7th printing 2017 edition},
  title = {An {{Introduction}} to {{Statistical Learning}}: With {{Applications}} in {{R}}},
  isbn = {978-1-4614-7137-0},
  shorttitle = {An {{Introduction}} to {{Statistical Learning}}},
  abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
  language = {English},
  publisher = {{Springer}},
  author = {Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani},
  month = {sep},
  year = {2017},
}

@Book{kuhnAppliedPredictiveModeling2018,
  address = {{New York}},
  edition = {1st ed. 2013, Corr. 2nd printing 2016 edition},
  title = {Applied {{Predictive Modeling}}},
  isbn = {978-1-4614-6848-6},
  abstract = {Winner of the 2014 Technometrics Ziegel Prize for Outstanding BookApplied Predictive Modeling covers the overall predictive modeling process, beginning with the crucial steps of data preprocessing, data splitting and foundations of model tuning.~ The text then provides intuitive explanations of numerous common and modern regression and classification techniques, always with an emphasis on illustrating and solving real data problems.~ Addressing practical concerns extends beyond model fitting to topics such as handling class imbalance, selecting predictors, and pinpointing causes of poor model performance\rule{1em}{1pt}all of which are problems that occur frequently in practice.~The text illustrates all parts of the modeling process through many hands-on, real-life examples.~ And every chapter contains extensive R code for each step of the process.~ The data sets and corresponding code are available in the book's companion AppliedPredictiveModeling R package, which is freely available on the CRAN archive.~This multi-purpose text can be used as an introduction to predictive models and the overall modeling process, a practitioner's reference handbook, or as a text for advanced undergraduate or graduate level predictive modeling courses.~ To that end, each chapter contains problem sets to help solidify the covered concepts and uses data available in the book's R package.~Readers and students interested in implementing the methods should have some basic knowledge of R.~ And a handful of the more advanced topics require some mathematical knowledge.},
  language = {English},
  publisher = {{Springer}},
  author = {Max Kuhn and Kjell Johnson},
  month = {mar},
  year = {2018},
}

@Article{hopkinsIndividualResponsesMade2015,
  title = {Individual Responses Made Easy},
  volume = {118},
  issn = {8750-7587},
  number = {12},
  journal = {Journal of Applied Physiology},
  doi = {10.1152/japplphysiol.00098.2015},
  author = {Will G. Hopkins},
  month = {jun},
  year = {2015},
  pages = {1444-1446},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2TP6EQSK/Hopkins - 2015 - Individual responses made easy.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/46HC7YLS/japplphysiol.00098.html},
}

@Article{hopkinsHowInterpretChanges2004,
  title = {How to {{Interpret Changes}} in an {{Athletic Performance Test}}},
  abstract = {When monitoring progression of an athlete with performance or other fitness tests, it is important to take into account the magnitude of the smallest worthwhile enhancement in performance and the uncertainty or noise in the test result. For elite athletes competing in sports as individuals, the smallest worthwhile enhancement would give the athlete an extra medal per 10 competitions; the required change in performance is 0.3 of the typical variation in an athlete's performance from competition to competition, or \textasciitilde{}0.31\% when expressed as a change in power output, depending on the sport. In team sports, where there is no direct relationship between team and test performance, an appropriate default for the smallest change in test performance is one-fifth of the between-athlete standard deviation (a standardized or Cohen effect size of 0.20). Noise in a test result is best expressed as the typical or standard error of measurement derived from a reliability study. The noise in most performance tests is greater than the smallest worthwhile difference, so assessments of changes in performance can be problematic. An exact but somewhat impractical solution is to present chances that the true change is beneficial, trivial, and harmful. A simpler approach is to apply systematic rules to decide whether the true change is beneficial, trivial, harmful, or unclear. Unrealistically large changes can also be partially discounted when tests are noisy.},
  language = {en},
  author = {Will G Hopkins},
  month = {nov},
  year = {2004},
  pages = {2},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/UDWHMNWC/Hopkins - How to Interpret Changes in an Athletic Performanc.pdf},
}

@Article{kingPointMinimalImportant2011,
  title = {A Point of Minimal Important Difference ({{MID}}): A Critique of Terminology and Methods},
  volume = {11},
  issn = {1473-7167, 1744-8379},
  shorttitle = {A Point of Minimal Important Difference ({{MID}})},
  language = {en},
  number = {2},
  journal = {Expert Review of Pharmacoeconomics \& Outcomes Research},
  doi = {10.1586/erp.11.9},
  author = {Madeleine T King},
  month = {apr},
  year = {2011},
  pages = {171-184},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/ZATLVG9F/King - 2011 - A point of minimal important difference (MID) a c.pdf},
}

@Article{anvariUsingAnchorBasedMethods2019,
  title = {Using {{Anchor}}-{{Based Methods}} to {{Determine}} the {{Smallest Effect Size}} of {{Interest}}},
  abstract = {Effect sizes are an important outcome of quantitative research because they allow researchers to communicate the practical significance of the findings. However, there are few guides for psychological researchers that explain how they can quantify which effect sizes are practically meaningful, and which are not. Being able to specify the smallest effect size that is considered practically meaningful facilitates the design of well-powered experiments and enables researchers to falsify predictions by rejecting effects larger than this effect size. We illustrate two methods used in clinical research to determine the minimally detectable difference: the smallest effect size that is associated with a subjectively noticeable change at the individual level. These anchor-based methods provide one possible approach for researchers to determine their smallest effect size of interest, and to interpret the effect size estimates observed in research lines. We discuss the limitations of applying anchor-based methods in psychology, and point out there is ample room for statistical and methodological improvement, but also highlight the potential for anchor-based methods to provide one approach to establish a smallest effect of interest in lines of research.},
  doi = {10.31234/osf.io/syp5a},
  author = {Farid Anvari and Daniel Lakens},
  month = {mar},
  year = {2019},
}

@Article{turnerDataAnalysisStrength2015,
  title = {Data {{Analysis}} for {{Strength}} and {{Conditioning Coaches}}: {{Using Excel}} to {{Analyze Reliability}}, {{Differences}}, and {{Relationships}}},
  volume = {37},
  issn = {1524-1602},
  shorttitle = {Data {{Analysis}} for {{Strength}} and {{Conditioning Coaches}}},
  language = {en},
  number = {1},
  journal = {Strength and Conditioning Journal},
  doi = {10.1519/SSC.0000000000000113},
  author = {Anthony Turner and Jon Brazier and Chris Bishop and Shyam Chavda and Jon Cree and Paul Read},
  month = {feb},
  year = {2015},
  pages = {76-83},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/4UTCHCRV/Turner et al. - 2015 - Data Analysis for Strength and Conditioning Coache.pdf},
}

@Article{lakensEquivalenceTestingPsychological2018,
  title = {Equivalence {{Testing}} for {{Psychological Research}}: {{A Tutorial}}},
  volume = {1},
  issn = {2515-2459, 2515-2467},
  shorttitle = {Equivalence {{Testing}} for {{Psychological Research}}},
  language = {en},
  number = {2},
  journal = {Advances in Methods and Practices in Psychological Science},
  doi = {10.1177/2515245918770963},
  author = {Dani{\"e}l Lakens and Anne M. Scheel and Peder M. Isager},
  month = {jun},
  year = {2018},
  pages = {259-269},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/SQZF6YGD/Lakens et al. - 2018 - Equivalence Testing for Psychological Research A .pdf},
}
@Article{swintonStatisticalFrameworkInterpret2018,
  title = {A {{Statistical Framework}} to {{Interpret Individual Response}} to {{Intervention}}: {{Paving}} the {{Way}} for {{Personalized Nutrition}} and {{Exercise Prescription}}},
  volume = {5},
  issn = {2296-861X},
  shorttitle = {A {{Statistical Framework}} to {{Interpret Individual Response}} to {{Intervention}}},
  abstract = {The concept of personalized nutrition and exercise prescription represents a topical and exciting progression for the discipline given the large inter-individual variability that exists in response to virtually all performance and health related interventions. Appropriate interpretation of intervention-based data from an individual or group of individuals requires practitioners and researchers to consider a range of concepts including the confounding influence of measurement error and biological variability. In addition, the means to quantify likely statistical and practical improvements are facilitated by concepts such as confidence intervals (CIs) and smallest worthwhile change (SWC). The purpose of this review is to provide accessible and applicable recommendations for practitioners and researchers that interpret, and report personalized data. To achieve this, the review is structured in three sections that progressively develop a statistical framework. Section 1 explores fundamental concepts related to measurement error and describes how typical error and CIs can be used to express uncertainty in baseline measurements. Section 2 builds upon these concepts and demonstrates how CIs can be combined with the concept of SWC to assess whether meaningful improvements occur post-intervention. Finally, section 3 introduces the concept of biological variability and discusses the subsequent challenges in identifying individual response and nonresponse to an intervention. Worked numerical examples and interactive Supplementary Material are incorporated to solidify concepts and assist with implementation in practice.},
  language = {en},
  journal = {Frontiers in Nutrition},
  doi = {10.3389/fnut.2018.00041},
  author = {Paul A. Swinton and Ben Stephens Hemingway and Bryan Saunders and Bruno Gualano and Eimear Dolan},
  month = {may},
  year = {2018},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CVG444SS/Swinton et al. - 2018 - A Statistical Framework to Interpret Individual Re.pdf},
}
@Book{henryGgstanceHorizontalGgplot22019,
  title = {Ggstance: {{Horizontal}} 'ggplot2' {{Components}}},
  author = {Lionel Henry and Hadley Wickham and Winston Chang},
  year = {2019},
}
@Article{caldwellBasicStatisticalConsiderations2019,
  title = {Basic Statistical Considerations for Physiology: {{The}} Journal {{{\emph{Temperature}}}} Toolbox},
  issn = {2332-8940, 2332-8959},
  shorttitle = {Basic Statistical Considerations for Physiology},
  language = {en},
  journal = {Temperature},
  doi = {10.1080/23328940.2019.1624131},
  author = {Aaron R. Caldwell and Samuel N. Cheuvront},
  month = {jun},
  year = {2019},
  pages = {1-30},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2T2M2GVS/Caldwell and Cheuvront - 2019 - Basic statistical considerations for physiology T.pdf},
}
@Book{rstudioteamRStudioIntegratedDevelopment2016,
  address = {{Boston, MA}},
  title = {{{RStudio}}: {{Integrated Development Environment}} for {{R}}},
  publisher = {{RStudio, Inc.}},
  author = {{RStudio Team}},
  year = {2016},
}

@Book{rstudioteamRStudioIntegratedDevelopment2016,
  address = {{Boston, MA}},
  title = {{{RStudio}}: {{Integrated Development Environment}} for {{R}}},
  publisher = {{RStudio, Inc.}},
  author = {{RStudio Team}},
  year = {2016},
}
@Book{rcoreteamLanguageEnvironmentStatistical2018,
  address = {{Vienna, Austria}},
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  publisher = {{R Foundation for Statistical Computing}},
  author = {{R Core Team}},
  year = {2018},
}
@Book{xieMarkdownDefinitiveGuide2018,
  address = {{Boca Raton, Florida}},
  title = {R {{Markdown}}: {{The Definitive Guide}}},
  publisher = {{Chapman and Hall/CRC}},
  author = {Yihui Xie and J. J. Allaire and Garrett Grolemund},
  year = {2018},
}
@Article{hopkinsMeasuresReliabilitySports2000,
  title = {Measures of {{Reliability}} in {{Sports Medicine}} and {{Science}}},
  language = {en},
  journal = {Sports Med},
  author = {Will G Hopkins},
  year = {2000},
  pages = {15},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/XQMCXXI9/Hopkins - 2000 - Measures of Reliability in Sports Medicine and Sci.pdf},
}

@Misc{hopkinsSocraticDialogueComparison2010,
  title = {A {{Socratic Dialogue}} on {{Comparison}} of {{Measures}}},
  abstract = {The utility of a practical or other measure can be assessed in a validity study, in which values of the measure are compared with those of a criterion measure taken concurrently in a sample of subjects.  A scatterplot of criterion vs practical values provides a qualitative assessment of non-linearity, random error and systematic error in the relationship between the two measures, while the statistics of linear regression (equation of the line or curve, standard error of the estimate, correlation coefficient) provide not only a quantitative assessment but are also useful for interpreting and adjusting values and effects involving the practical measure.  Another method for comparing two measures, suggested by Bland and Altman, is based on a plot and analysis of the difference between the measures. Although in widespread use, the Bland-Altman method is inappropriate for validity studies: the plot shows systematic error incorrectly and the assessment of interchangeability does not properly reflect the utility of the practical measure.  If there is no criterion measure in a measure-comparison study, use of regression or Bland-Altman approaches is pointless without a strategy to rank the measures. Comparison of correlation coefficients between a sufficient number of measures is one such strategy. KEYWORDS: bias, Bland-Altman, correlation, criterion, limits of agreement, practical, standard error of the estimate, typical error, validity.},
  journal = {Sportscience.org},
  howpublished = {http://www.sportsci.org/2010/wghmeasures.htm},
  author = {Will G Hopkins},
  year = {2010},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/99TP8N55/wghmeasures.html},
  note = {Sportscience 14, 15-21, 2010 (sportsci.org/2010/wghmeasures.htm)},
}

@Misc{hopkinsUnderstandingStatisticsUsing2007,
  title = {Understanding {{Statistics}} by {{Using Spreadsheets}} to {{Generate}} and {{Analyze Samples}}},
  abstract = {The random number and probability distribution functions in Excel allow the user to easily generate samples that simulate data typical of any kind of biomedical study. The act of generating the samples should provide the user with an implicit understanding of fundamental statistical concepts, including variables, probability, independence, sampling variation, linear modeling, random error, fixed effects, random effects, and individual responses. Analysis of the samples, which is essentially an attempt to recover the formulae that generated the samples, should reinforce these concepts and develop others related to statistical inference, including bias, confidence limits, statistical significance, and chances of benefit and harm. The spreadsheets accompanying this article provide examples of generation and analysis of data for reliability and validity studies and for simple and covariate-adjusted comparisons of group means without and with repeated measurement. An example is also given for generation of a binary variable for data simulating events, such as the occurrence of injuries, but the analysis by generalized linear modeling is currently not available in these spreadsheets. KEYWORDS: confidence limits, data analysis, probability, random number, research design, simulation},
  journal = {Sportscience.org},
  howpublished = {https://www.sportsci.org/2007/wghstats.htm},
  author = {Will G Hopkins},
  year = {2007},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/VIDDZ9EN/wghstats.html},
}

@Article{hopkinsSpreadsheetsAnalysisValidity2015,
  title = {Spreadsheets for Analysis of Validity and Reliability},
  language = {en},
  journal = {Sportscience.org},
  author = {Will Hopkins},
  year = {2015},
  pages = {9},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/D9PGIRVJ/Hopkins - 2015 - Spreadsheets for analysis of validity and reliabil.pdf},
}

@Misc{hopkinsUnderstandingStatisticsUsing2007,
  title = {Understanding {{Statistics}} by {{Using Spreadsheets}} to {{Generate}} and {{Analyze Samples}}},
  abstract = {The random number and probability distribution functions in Excel allow the user to easily generate samples that simulate data typical of any kind of biomedical study. The act of generating the samples should provide the user with an implicit understanding of fundamental statistical concepts, including variables, probability, independence, sampling variation, linear modeling, random error, fixed effects, random effects, and individual responses. Analysis of the samples, which is essentially an attempt to recover the formulae that generated the samples, should reinforce these concepts and develop others related to statistical inference, including bias, confidence limits, statistical significance, and chances of benefit and harm. The spreadsheets accompanying this article provide examples of generation and analysis of data for reliability and validity studies and for simple and covariate-adjusted comparisons of group means without and with repeated measurement. An example is also given for generation of a binary variable for data simulating events, such as the occurrence of injuries, but the analysis by generalized linear modeling is currently not available in these spreadsheets. KEYWORDS: confidence limits, data analysis, probability, random number, research design, simulation},
  journal = {Sportscience.org},
  howpublished = {https://www.sportsci.org/2007/wghstats.htm},
  author = {Will G Hopkins},
  year = {2007},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2FUPCIT5/wghstats.html},
}

@Misc{hopkinsSocraticDialogueComparison2010,
  title = {A {{Socratic Dialogue}} on {{Comparison}} of {{Measures}}},
  abstract = {The utility of a practical or other measure can be assessed in a validity study, in which values of the measure are compared with those of a criterion measure taken concurrently in a sample of subjects.  A scatterplot of criterion vs practical values provides a qualitative assessment of non-linearity, random error and systematic error in the relationship between the two measures, while the statistics of linear regression (equation of the line or curve, standard error of the estimate, correlation coefficient) provide not only a quantitative assessment but are also useful for interpreting and adjusting values and effects involving the practical measure.  Another method for comparing two measures, suggested by Bland and Altman, is based on a plot and analysis of the difference between the measures. Although in widespread use, the Bland-Altman method is inappropriate for validity studies: the plot shows systematic error incorrectly and the assessment of interchangeability does not properly reflect the utility of the practical measure.  If there is no criterion measure in a measure-comparison study, use of regression or Bland-Altman approaches is pointless without a strategy to rank the measures. Comparison of correlation coefficients between a sufficient number of measures is one such strategy. KEYWORDS: bias, Bland-Altman, correlation, criterion, limits of agreement, practical, standard error of the estimate, typical error, validity.},
  journal = {Sportscience.org},
  howpublished = {http://www.sportsci.org/2010/wghmeasures.htm},
  author = {Will G Hopkins},
  year = {2010},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/S8K5KJJ3/wghmeasures.html},
  note = {Sportscience 14, 15-21, 2010 (sportsci.org/2010/wghmeasures.htm)},
}

@Article{hopkinsMeasuresReliabilitySports2000,
  title = {Measures of {{Reliability}} in {{Sports Medicine}} and {{Science}}},
  language = {en},
  journal = {Sports Med},
  author = {Will G Hopkins},
  year = {2000},
  pages = {15},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/26ELTY8S/Hopkins - 2000 - Measures of Reliability in Sports Medicine and Sci.pdf},
}
@Article{albaneseMinervaMinepyEngine2012,
  title = {Minerva and Minepy: A {{C}} Engine for the {{MINE}} Suite and Its {{R}}, {{Python}} and {{MATLAB}} Wrappers},
  journal = {Bioinformatics},
  author = {Davide Albanese and Michele Filosi and Roberto Visintainer and Samantha Riccadonna and Giuseppe Jurman and Cesare Furlanello},
  year = {2012},
  pages = {bts707},
}
@Article{reshefDetectingNovelAssociations2011,
  title = {Detecting {{Novel Associations}} in {{Large Data Sets}}},
  volume = {334},
  issn = {0036-8075, 1095-9203},
  language = {en},
  number = {6062},
  journal = {Science},
  doi = {10.1126/science.1205438},
  author = {D. N. Reshef and Y. A. Reshef and H. K. Finucane and S. R. Grossman and G. McVean and P. J. Turnbaugh and E. S. Lander and M. Mitzenmacher and P. C. Sabeti},
  month = {dec},
  year = {2011},
  pages = {1518-1524},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/R2BHZX4P/Reshef et al. - 2011 - Detecting Novel Associations in Large Data Sets.pdf},
}
@Book{foremanDataSmartUsing2014,
  address = {{Hoboken, New Jersey}},
  title = {Data Smart: Using Data Science to Transform Information into Insight},
  isbn = {978-1-118-66146-8},
  lccn = {QA76.9.D343 F67 2014},
  shorttitle = {Data Smart},
  abstract = {{"}Data Science gets thrown around in the press like it's magic. Major retailers are predicting everything from when their customers are pregnant to when they want a new pair of Chuck Taylors. It's a brave new world where seemingly meaningless data can be transformed into valuable insight to drive smart business decisions. But how does one exactly do data science? Do you have to hire one of these priests of the dark arts, the {"}data scientist,{"} to extract this gold from your data? Nope. Data science is little more than using straight-forward steps to process raw data into actionable insight. And in Data Smart, author and data scientist John Foreman will show you how that's done within the familiar environment of a spreadsheet.{"}--},
  publisher = {{John Wiley \& Sons}},
  author = {John W. Foreman},
  year = {2014},
  keywords = {Data mining},
  note = {OCLC: ocn858311212},
}
@Article{borsboomTheoreticalStatusLatent2003,
  title = {The Theoretical Status of Latent Variables.},
  volume = {110},
  issn = {1939-1471, 0033-295X},
  language = {en},
  number = {2},
  journal = {Psychological Review},
  doi = {10.1037/0033-295X.110.2.203},
  author = {Denny Borsboom and Gideon J. Mellenbergh and Jaap {van Heerden}},
  month = {apr},
  year = {2003},
  pages = {203-219},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/XWJW4RZL/Borsboom et al. - 2003 - The theoretical status of latent variables..pdf},
}

@Article{borsboomLatentVariableTheory2008,
  title = {Latent {{Variable Theory}}},
  volume = {6},
  issn = {1536-6367, 1536-6359},
  abstract = {This paper formulates a metatheoretical framework for latent variable modeling. It does so by spelling out the difference between observed and latent variables. This difference is argued to be purely epistemic in nature: We treat a variable as observed when the inference from data structure to variable structure can be made with certainty and as latent when this inference is prone to error. This difference in epistemic accessibility is argued to be directly related to the datagenerating process, i.e., the process that produces the concrete data patterns on which statistical analyses are executed. For a variable to count as observed through a set of data patterns, the relation between variable structure and data structure should be (a) deterministic, (b) causally isolated, and (c) of equivalent cardinality. When any of these requirements is violated, (part of) the variable structure should be considered latent. It is argued that, on these criteria, observed variables are rare to nonexistent in psychology; hence, psychological variables should be considered latent until proven observed.},
  language = {en},
  number = {1-2},
  journal = {Measurement: Interdisciplinary Research \& Perspective},
  doi = {10.1080/15366360802035497},
  author = {Denny Borsboom},
  month = {may},
  year = {2008},
  pages = {25-53},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/G6UEV5K8/Borsboom - 2008 - Latent Variable Theory.pdf},
}

@Book{kabacoffActionDataAnalysis2015,
  address = {{Shelter Island}},
  edition = {Second edition},
  title = {R in Action: Data Analysis and Graphics with {{R}}},
  isbn = {978-1-61729-138-8},
  lccn = {QA276.45.R3 K33 2015},
  shorttitle = {R in Action},
  publisher = {{Manning}},
  author = {Robert Kabacoff},
  year = {2015},
  keywords = {Data processing,R (Computer program language),Statistics},
}

@Book{everittIntroductionAppliedMultivariate2011,
  address = {{New York}},
  series = {Use {{R}}!},
  title = {An Introduction to Applied Multivariate Analysis with {{R}}},
  isbn = {978-1-4419-9649-7 978-1-4419-9650-3},
  lccn = {QA278 .E87 2011},
  abstract = {{"}The majority of data sets collected by researchers in all disciplines are multivariate, meaning that several measurements, observations, or recordings are taken on each of the units in the data set. These units might be human subjects, archaeological artifacts, countries, or a vast variety of other things. In a few cases, it may be sensible to isolate each variable and study it separately, but in most instances all the variables need to be examined simultaneously in order to fully grasp the structure and key features of the data. For this purpose, one or another method of multivariate analysis might be helpful, and it is with such methods that this book is largely concerned. Multivariate analysis includes methods both for describing and exploring such data and for making formal inferences about them. The aim of all the techniques is, in general sense, to display or extract the signal in the data in the presence of noise and to find out what the data show us in the midst of their apparent chaos. An Introduction to Applied Multivariate Analysis with R explores the correct application of these methods so as to extract as much information as possible from the data at hand, particularly as some type of graphical representation, via the R software. Throughout the book, the authors give many examples of R code used to apply the multivariate techniques to multivariate data.{"}--Publisher's description},
  publisher = {{Springer}},
  author = {Brian Everitt and Torsten Hothorn},
  year = {2011},
  keywords = {Data processing,Multivariate Analyse,Multivariate analysis,R (Computer program language),R (Programm)},
  note = {OCLC: ocn732344476},
}

@Book{finchLatentVariableModeling2015,
  address = {{New York}},
  title = {Latent Variable Modeling with {{R}}},
  isbn = {978-0-415-83244-1 978-0-415-83245-8},
  lccn = {QA278.6 .F56 2015},
  abstract = {{"}This text demonstrates how to conduct latent variable modeling in R. Techniques that can be analyzed using the free program R are showcased including exploratory and confirmatory factor analysis, structural equation modeling (SEM), latent growth curve modeling, item response theory (IRT), and latent class analysis. Easy to follow demonstrations of how to conduct latent variable modeling in R are provided along with descriptions of the major features of the models,their specialized uses, and a full interpretation of the results. Every R command necessary for conducting the analyses is described so readers can directly apply the R functions to their own data. Each chapter features a complete analysis of one or more example datasets including a demonstration of the analysis of the data using R, along with a discussion of relevant theory that includes a full description of the models, the assumptions underlying each model, and statistical details of estimation, hypothesis testing, and more to help readers better understand the models and interpret the results. Some of the examples represent data that is not perfectly {"}behaved{"} so as to provide a more realistic view of situations readers will likely encounter with their own data. Detailed explanations of input statements help readers generalize what they learn to their own analyses. Each chapter features an introduction, summary, and exercises involving the application of the model(s), and a list of further readings with an emphasis on related texts that provide more detailed theoretical coverage. A full glossary of the key terms, a cheat sheet that reviews the key R commands, and answers to half of the exercises are provided at the end of the book{"}--},
  publisher = {{Routledge, Taylor \& Francis Group}},
  author = {W. Holmes Finch and Brian F. French},
  year = {2015},
  keywords = {R (Computer program language),Latent structure analysis,Latent variables,PSYCHOLOGY / Assessment; Testing \& Measurement,PSYCHOLOGY / Research \& Methodology,PSYCHOLOGY / Statistics},
}

@Book{beaujeanLatentVariableModeling2014,
  address = {{New York}},
  title = {Latent Variable Modeling Using {{R}}: A Step by Step Guide},
  isbn = {978-1-84872-699-4 978-1-84872-698-7},
  lccn = {QA278.6 .B43 2014},
  shorttitle = {Latent Variable Modeling Using {{R}}},
  publisher = {{Routledge/Taylor \& Francis Group}},
  author = {A. Alexander Beaujean},
  year = {2014},
  keywords = {R (Computer program language),Latent structure analysis,Latent variables},
  note = {OCLC: ocn868199963},
}
@Article{breimanStatisticalModelingTwo2001,
  title = {Statistical {{Modeling}}: {{The Two Cultures}}},
  volume = {16},
  abstract = {Thereare twoculturesin the use ofstatisticalmodelingto reachconclusionsfromdata. One assumes thatthe data are generated bya givenstochasticdata model.The otheruses algorithmimc odelsand treatsthe data mechanismas unknownT. he statisticalcommunityhas beencommittetdothealmostexclusiveuse ofdata models.Thiscommitmenthas ledtoirrelevantheoryq,uestionableconclusionsa,nd has kept statisticiansfromworkingon a largerangeofinterestingcurrentproblems.Algorithmimc odelingb, othin theoryand practice,has developed rapidlyin fieldsoutsidestatisticsI.t can be used bothon largecomplex data sets and as a moreaccurateand informativaelternativeto data modelingon smallerdata sets. If our goal as a fieldis to use data to solveproblemst,henwe need to moveawayfromexclusivedependence on data modelsand adopta morediverseset oftools.},
  language = {en},
  number = {3},
  journal = {Statistical Science},
  author = {Leo Breiman},
  year = {2001},
  pages = {199-215},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/B63X8LTL/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf},
}

@Article{shmueliExplainPredict2010,
  title = {To {{Explain}} or to {{Predict}}?},
  volume = {25},
  issn = {0883-4237},
  abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
  language = {en},
  number = {3},
  journal = {Statistical Science},
  doi = {10.1214/10-STS330},
  author = {Galit Shmueli},
  month = {aug},
  year = {2010},
  pages = {289-310},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/TQZ23S6G/Shmueli - 2010 - To Explain or to Predict.pdf},
}

@Article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  volume = {12},
  issn = {1745-6916, 1745-6924},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  language = {en},
  number = {6},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691617693393},
  author = {Tal Yarkoni and Jacob Westfall},
  month = {nov},
  year = {2017},
  pages = {1100-1122},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/WQYVMIYX/Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf},
}

@Article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  volume = {12},
  issn = {1745-6916, 1745-6924},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  language = {en},
  number = {6},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691617693393},
  author = {Tal Yarkoni and Jacob Westfall},
  month = {nov},
  year = {2017},
  pages = {1100-1122},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/29WGF7CL/Yarkoni and Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf},
}

@Article{shmueliExplainPredict2010,
  title = {To {{Explain}} or to {{Predict}}?},
  volume = {25},
  issn = {0883-4237},
  abstract = {Statistical modeling is a powerful tool for developing and testing theories by way of causal explanation, prediction, and description. In many disciplines there is near-exclusive use of statistical modeling for causal explanation and the assumption that models with high explanatory power are inherently of high predictive power. Conflation between explanation and prediction is common, yet the distinction must be understood for progressing scientific knowledge. While this distinction has been recognized in the philosophy of science, the statistical literature lacks a thorough discussion of the many differences that arise in the process of modeling for an explanatory versus a predictive goal. The purpose of this article is to clarify the distinction between explanatory and predictive modeling, to discuss its sources, and to reveal the practical implications of the distinction to each step in the modeling process.},
  language = {en},
  number = {3},
  journal = {Statistical Science},
  doi = {10.1214/10-STS330},
  author = {Galit Shmueli},
  month = {aug},
  year = {2010},
  pages = {289-310},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/DN2NPCLC/Shmueli - 2010 - To Explain or to Predict.pdf},
}

@Article{breimanStatisticalModelingTwo2001,
  title = {Statistical {{Modeling}}: {{The Two Cultures}}},
  volume = {16},
  abstract = {Thereare twoculturesin the use ofstatisticalmodelingto reachconclusionsfromdata. One assumes thatthe data are generated bya givenstochasticdata model.The otheruses algorithmimc odelsand treatsthe data mechanismas unknownT. he statisticalcommunityhas beencommittetdothealmostexclusiveuse ofdata models.Thiscommitmenthas ledtoirrelevantheoryq,uestionableconclusionsa,nd has kept statisticiansfromworkingon a largerangeofinterestingcurrentproblems.Algorithmimc odelingb, othin theoryand practice,has developed rapidlyin fieldsoutsidestatisticsI.t can be used bothon largecomplex data sets and as a moreaccurateand informativaelternativeto data modelingon smallerdata sets. If our goal as a fieldis to use data to solveproblemst,henwe need to moveawayfromexclusivedependence on data modelsand adopta morediverseset oftools.},
  language = {en},
  number = {3},
  journal = {Statistical Science},
  author = {Leo Breiman},
  year = {2001},
  pages = {199-215},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/SW47N62P/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf},
}
@Book{pearlCausalInferenceStatistics2016,
  address = {{Chichester, West Sussex}},
  edition = {1 edition},
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}}},
  isbn = {978-1-119-18684-7},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality.~ Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  language = {English},
  publisher = {{Wiley}},
  author = {Judea Pearl and Madelyn Glymour and Nicholas P. Jewell},
  month = {mar},
  year = {2016},
}

@Misc{hernanCausalDiagramsDraw2017,
  title = {Causal {{Diagrams}}: {{Draw Your Assumptions Before Your Conclusions Course}} | {{PH559x}} | {{edX}}},
  abstract = {Welcome to Causal Diagrams: Draw Your Assumptions Before Your Conclusions!

This introductory course to causal diagrams teaches you how to translate expert knowledge into a causal diagrams. By the end of the course you will be able:

To draw causal diagrams under different assumptions
To identify common biases using causal diagrams
To guide data analysis using causal diagrams
Before we get started, please take a moment read the Syllabus and the Frequently Asked Questions.

Questions and Support

If you have any questions about course content, please post your question on the appropriate discussion board. You can always go to the boards using the discussion tab on the top of the screen. Alternatively, there is a link to the relevant discussion board at the end of each lesson and case.

If you have any questions about the course logistics you should post your questions on the course logistics board. Please first read over the other posts before posting in case the questions has already been asked and answered.

If you have any questions about the edX platform or the verified certificate, you can click on the button on the left of the screen that says {"}Support.{"}

Thank you

Thank you for joining us! We hope that you find this course, not only useful and informative, but enjoyable as well.

Let's get started.},
  journal = {edX},
  howpublished = {https://courses.edx.org/courses/course-v1:HarvardX+PH559x+3T2017/course/},
  author = {Miguel A. Hernán},
  month = {sep},
  year = {2017},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/RTY7LZ3S/course.html},
}

@Article{pearlSevenToolsCausal2019,
  title = {The Seven Tools of Causal Inference, with Reflections on Machine Learning},
  volume = {62},
  issn = {00010782},
  language = {en},
  number = {3},
  journal = {Communications of the ACM},
  doi = {10.1145/3241036},
  author = {Judea Pearl},
  month = {feb},
  year = {2019},
  pages = {54-60},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/KUZB3HCH/Pearl - 2019 - The seven tools of causal inference, with reflecti.pdf},
}

@Book{hernanCausalInference2019,
  address = {{Boca Raton}},
  title = {Causal {{Inference}}},
  publisher = {{Chapman \& Hall/CRC}},
  author = {Miguel A. Hernán and JM Robins},
  year = {2019, forthcoming},
}

@Book{pearlCausalInferenceStatistics2016,
  address = {{Chichester, West Sussex}},
  edition = {1 edition},
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}}},
  isbn = {978-1-119-18684-7},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality.~ Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  language = {English},
  publisher = {{Wiley}},
  author = {Judea Pearl and Madelyn Glymour and Nicholas P. Jewell},
  month = {mar},
  year = {2016},
}

@Misc{hernanCausalDiagramsDraw2017,
  title = {Causal {{Diagrams}}: {{Draw Your Assumptions Before Your Conclusions Course}} | {{PH559x}} | {{edX}}},
  abstract = {Welcome to Causal Diagrams: Draw Your Assumptions Before Your Conclusions!

This introductory course to causal diagrams teaches you how to translate expert knowledge into a causal diagrams. By the end of the course you will be able:

To draw causal diagrams under different assumptions
To identify common biases using causal diagrams
To guide data analysis using causal diagrams
Before we get started, please take a moment read the Syllabus and the Frequently Asked Questions.

Questions and Support

If you have any questions about course content, please post your question on the appropriate discussion board. You can always go to the boards using the discussion tab on the top of the screen. Alternatively, there is a link to the relevant discussion board at the end of each lesson and case.

If you have any questions about the course logistics you should post your questions on the course logistics board. Please first read over the other posts before posting in case the questions has already been asked and answered.

If you have any questions about the edX platform or the verified certificate, you can click on the button on the left of the screen that says {"}Support.{"}

Thank you

Thank you for joining us! We hope that you find this course, not only useful and informative, but enjoyable as well.

Let's get started.},
  journal = {edX},
  howpublished = {https://courses.edx.org/courses/course-v1:HarvardX+PH559x+3T2017/course/},
  author = {Miguel A. Hernán},
  month = {sep},
  year = {2017},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/PBW53ZZV/course.html},
}
@Article{rohrerThinkingClearlyCorrelations2018,
  title = {Thinking {{Clearly About Correlations}} and {{Causation}}: {{Graphical Causal Models}} for {{Observational Data}}},
  volume = {1},
  issn = {2515-2459},
  shorttitle = {Thinking {{Clearly About Correlations}} and {{Causation}}},
  abstract = {Correlation does not imply causation; but often, observational data are the only option, even though the research question at hand involves causality. This article discusses causal inference based on observational data, introducing readers to graphical causal models that can provide a powerful tool for thinking more clearly about the interrelations between variables. Topics covered include the rationale behind the statistical control of third variables, common procedures for statistical control, and what can go wrong during their implementation. Certain types of third variables\textemdash{}colliders and mediators\textemdash{}should not be controlled for because that can actually move the estimate of an association away from the value of the causal effect of interest. More subtle variations of such harmful control include using unrepresentative samples, which can undermine the validity of causal conclusions, and statistically controlling for mediators. Drawing valid causal inferences on the basis of observational data is not a mechanistic procedure but rather always depends on assumptions that require domain knowledge and that can be more or less plausible. However, this caveat holds not only for research based on observational data, but for all empirical research endeavors.},
  language = {en},
  number = {1},
  journal = {Advances in Methods and Practices in Psychological Science},
  doi = {10.1177/2515245917745629},
  author = {Julia M. Rohrer},
  month = {mar},
  year = {2018},
  pages = {27-42},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/J4F2A6TI/Rohrer - 2018 - Thinking Clearly About Correlations and Causation.pdf},
}

@Article{hernanDoesWaterKill2016,
  title = {Does Water Kill? {{A}} Call for Less Casual Causal Inferences},
  volume = {26},
  issn = {1047-2797},
  shorttitle = {Does Water Kill?},
  abstract = {``Can this number be interpreted as a causal effect?'' is a key question for scientists and decision makers. The potential outcomes approach, a quantitative counterfactual theory, describes conditions under which the question can be answered affirmatively. This article reviews one of those conditions, known as consistency, and its implications for real world decisions.},
  number = {10},
  journal = {Annals of epidemiology},
  doi = {10.1016/j.annepidem.2016.08.016},
  author = {Miguel A. Hernán},
  month = {oct},
  year = {2016},
  pages = {674-680},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/WMGTNVD8/Hernán - 2016 - Does water kill A call for less casual causal inf.pdf},
  pmid = {27641316},
  pmcid = {PMC5207342},
}

@Article{ledererControlConfoundingReporting2019,
  title = {Control of {{Confounding}} and {{Reporting}} of {{Results}} in {{Causal Inference Studies}}. {{Guidance}} for {{Authors}} from {{Editors}} of {{Respiratory}}, {{Sleep}}, and {{Critical Care Journals}}},
  volume = {16},
  issn = {2329-6933, 2325-6621},
  language = {en},
  number = {1},
  journal = {Annals of the American Thoracic Society},
  doi = {10.1513/AnnalsATS.201808-564PS},
  author = {David J. Lederer and Scott C. Bell and Richard D. Branson and James D. Chalmers and Rachel Marshall and David M. Maslove and David E. Ost and Naresh M. Punjabi and Michael Schatz and Alan R. Smyth and Paul W. Stewart and Samy Suissa and Alex A. Adjei and Cezmi A. Akdis and {\a'E}lie Azoulay and Jan Bakker and Zuhair K. Ballas and Philip G. Bardin and Esther Barreiro and Rinaldo Bellomo and Jonathan A. Bernstein and Vito Brusasco and Timothy G. Buchman and Sudhansu Chokroverty and Nancy A. Collop and James D. Crapo and Dominic A. Fitzgerald and Lauren Hale and Nicholas Hart and Felix J. Herth and Theodore J. Iwashyna and Gisli Jenkins and Martin Kolb and Guy B. Marks and Peter Mazzone and J. Randall Moorman and Thomas M. Murphy and Terry L. Noah and Paul Reynolds and Dieter Riemann and Richard E. Russell and Aziz Sheikh and Giovanni Sotgiu and Erik R. Swenson and Rhonda Szczesniak and Ronald Szymusiak and Jean-Louis Teboul and Jean-Louis Vincent},
  month = {jan},
  year = {2019},
  pages = {22-28},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/MDKWF5QP/Lederer et al. - 2019 - Control of Confounding and Reporting of Results in.pdf},
}

@Article{rohrerThinkingClearlyCorrelations2018,
  title = {Thinking {{Clearly About Correlations}} and {{Causation}}: {{Graphical Causal Models}} for {{Observational Data}}},
  volume = {1},
  issn = {2515-2459},
  shorttitle = {Thinking {{Clearly About Correlations}} and {{Causation}}},
  abstract = {Correlation does not imply causation; but often, observational data are the only option, even though the research question at hand involves causality. This article discusses causal inference based on observational data, introducing readers to graphical causal models that can provide a powerful tool for thinking more clearly about the interrelations between variables. Topics covered include the rationale behind the statistical control of third variables, common procedures for statistical control, and what can go wrong during their implementation. Certain types of third variables\textemdash{}colliders and mediators\textemdash{}should not be controlled for because that can actually move the estimate of an association away from the value of the causal effect of interest. More subtle variations of such harmful control include using unrepresentative samples, which can undermine the validity of causal conclusions, and statistically controlling for mediators. Drawing valid causal inferences on the basis of observational data is not a mechanistic procedure but rather always depends on assumptions that require domain knowledge and that can be more or less plausible. However, this caveat holds not only for research based on observational data, but for all empirical research endeavors.},
  language = {en},
  number = {1},
  journal = {Advances in Methods and Practices in Psychological Science},
  doi = {10.1177/2515245917745629},
  author = {Julia M. Rohrer},
  month = {mar},
  year = {2018},
  pages = {27-42},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/974R6H83/Rohrer - 2018 - Thinking Clearly About Correlations and Causation.pdf},
}
@Article{fisherLackGrouptoindividualGeneralizability2018,
  title = {Lack of Group-to-Individual Generalizability Is a Threat to Human Subjects Research},
  volume = {115},
  issn = {0027-8424, 1091-6490},
  language = {en},
  number = {27},
  journal = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1711978115},
  author = {Aaron J. Fisher and John D. Medaglia and Bertus F. Jeronimus},
  month = {jul},
  year = {2018},
  pages = {E6106-E6115},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/Q6UBKZVT/Fisher et al. - 2018 - Lack of group-to-individual generalizability is a .pdf},
}

@Article{fisherLackGrouptoindividualGeneralizability2018,
  title = {Lack of Group-to-Individual Generalizability Is a Threat to Human Subjects Research},
  volume = {115},
  issn = {0027-8424, 1091-6490},
  language = {en},
  number = {27},
  journal = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1711978115},
  author = {Aaron J. Fisher and John D. Medaglia and Bertus F. Jeronimus},
  month = {jul},
  year = {2018},
  pages = {E6106-E6115},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/A5ILFY8Q/Fisher et al. - 2018 - Lack of group-to-individual generalizability is a .pdf},
}
@Book{hockingDirectlabelsDirectLabels2018,
  title = {Directlabels: {{Direct Labels}} for {{Multicolor Plots}}},
  author = {Toby Dylan Hocking},
  year = {2018},
}

@Book{hockingDirectlabelsDirectLabels2018,
  title = {Directlabels: {{Direct Labels}} for {{Multicolor Plots}}},
  author = {Toby Dylan Hocking},
  year = {2018},
}
@Book{carseyMonteCarloSimulation2013,
  address = {{Los Angeles}},
  edition = {1 edition},
  title = {Monte {{Carlo Simulation}} and {{Resampling Methods}} for {{Social Science}}},
  isbn = {978-1-4522-8890-1},
  abstract = {Taking the topics of a quantitative methodology course and illustrating them through Monte Carlo simulation, Monte Carlo Simulation and Resampling Methods for Social Science, by Thomas M. Carsey and Jeffrey J. Harden, examines abstract pr},
  language = {English},
  publisher = {{Sage Publications, Inc}},
  author = {Thomas Carsey and Jeffrey Harden},
  month = {aug},
  year = {2013},
}

@Book{carseyMonteCarloSimulation2013,
  address = {{Los Angeles}},
  edition = {1 edition},
  title = {Monte {{Carlo Simulation}} and {{Resampling Methods}} for {{Social Science}}},
  isbn = {978-1-4522-8890-1},
  abstract = {Taking the topics of a quantitative methodology course and illustrating them through Monte Carlo simulation, Monte Carlo Simulation and Resampling Methods for Social Science, by Thomas M. Carsey and Jeffrey J. Harden, examines abstract pr},
  language = {English},
  publisher = {{Sage Publications, Inc}},
  author = {Thomas Carsey and Jeffrey Harden},
  month = {aug},
  year = {2013},
}
@Article{rousseletPracticalIntroductionBootstrap,
  title = {A Practical Introduction to the Bootstrap: A Versatile Method to Make Inferences by Using Data-Driven Simulations},
  shorttitle = {A Practical Introduction to the Bootstrap},
  abstract = {The bootstrap is a versatile technique that relies on data-driven simulations to make statistical inferences. When combined with robust estimators, the bootstrap can afford much more powerful and flexible inferences than is possible with standard approaches such as t-tests on means. In this R tutorial, we use detailed illustrations of bootstrap simulations to give readers an intuition of what the bootstrap does and how it can be applied to solve many practical problems, such as building confidence intervals for many aspects of the data. In particular, we illustrate how to build confidence intervals for measures of location, including measures of central tendency, in the one-sample case, for two independent and two dependent groups. We also demonstrate how to compare correlation coefficients using the bootstrap and to perform simulations to determine if the bootstrap is fit for purpose for a particular application. The tutorial also addresses two widespread misconceptions about the bootstrap: that it makes no assumptions about the data, and that it leads to robust inferences on its own. The tutorial focuses on detailed graphical descriptions, with data and code available online to reproduce the figures and analyses in the article (https://osf.io/8b4t5/).},
  doi = {10.31234/osf.io/h8ft7},
  author = {Guillaume A Rousselet and Cyril R Pernet and Rand R. Wilcox},
}
@Book{molnarInterpretableMachineLearning2018,
  title = {{Interpretable Machine Learning}},
  abstract = {This book teaches you how to make machine learning models more interpretable.},
  language = {undefined},
  publisher = {{Leanpub}},
  author = {Christoph Molnar},
  month = {feb},
  year = {2018},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/RRCWNINP/interpretable-machine-learning.html},
}

@Book{pedersenLimeLocalInterpretable2018,
  title = {Lime: {{Local Interpretable Model}}-{{Agnostic Explanations}}},
  author = {Thomas Lin Pedersen and Micha{\"e}l Benesty},
  year = {2018},
}

@Book{pedersenLimeLocalInterpretable2018,
  title = {Lime: {{Local Interpretable Model}}-{{Agnostic Explanations}}},
  author = {Thomas Lin Pedersen and Micha{\"e}l Benesty},
  year = {2018},
}

@Book{molnarInterpretableMachineLearning2018,
  title = {{Interpretable Machine Learning}},
  abstract = {This book teaches you how to make machine learning models more interpretable.},
  language = {undefined},
  publisher = {{Leanpub}},
  author = {Christoph Molnar},
  month = {feb},
  year = {2018},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CU35BARN/interpretable-machine-learning.html},
}
@Article{ribeiroWhyShouldTrust2016,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.04938},
  primaryclass = {cs, stat},
  title = {{"}{{Why Should I Trust You}}?{"}: {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {{"}{{Why Should I Trust You}}?},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  journal = {arXiv:1602.04938 [cs, stat]},
  author = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  month = {feb},
  year = {2016},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/AQQ8CGSG/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/AYI6Y6S6/1602.04938.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2S6VV47Y/1602.html},
}

@Article{ribeiroWhyShouldTrust2016,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.04938},
  primaryclass = {cs, stat},
  title = {{"}{{Why Should I Trust You}}?{"}: {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {{"}{{Why Should I Trust You}}?},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  journal = {arXiv:1602.04938 [cs, stat]},
  author = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  month = {feb},
  year = {2016},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/NA67GUPV/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/YH3MDKMV/1602.04938.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/8LZ5PF8V/1602.html},
}
@Article{millerExplanationArtificialIntelligence2017,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.07269},
  primaryclass = {cs},
  title = {Explanation in {{Artificial Intelligence}}: {{Insights}} from the {{Social Sciences}}},
  shorttitle = {Explanation in {{Artificial Intelligence}}},
  abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a `good' explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
  journal = {arXiv:1706.07269 [cs]},
  author = {Tim Miller},
  month = {jun},
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/NW2T5TLR/Miller - 2017 - Explanation in Artificial Intelligence Insights f.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/J3MGCCEZ/1706.html},
}
@Article{molnarImlPackageInterpretable2018,
  title = {Iml: {{An R}} Package for {{Interpretable Machine Learning}}},
  volume = {3},
  number = {26},
  journal = {JOSS},
  doi = {10.21105/joss.00786},
  author = {Christoph Molnar and Bernd Bischl and Giuseppe Casalicchio},
  year = {2018},
  pages = {786},
}

@Article{molnarImlPackageInterpretable2018,
  title = {Iml: {{An R}} Package for {{Interpretable Machine Learning}}},
  volume = {3},
  number = {26},
  journal = {JOSS},
  doi = {10.21105/joss.00786},
  author = {Christoph Molnar and Bernd Bischl and Giuseppe Casalicchio},
  year = {2018},
  pages = {786},
}
@Book{kleinbergWhyGuideFinding2015,
  address = {{Beijing ; Boston}},
  edition = {1 edition},
  title = {Why: {{A Guide}} to {{Finding}} and {{Using Causes}}},
  isbn = {978-1-4919-4964-1},
  shorttitle = {Why},
  abstract = {Can drinking coffee help people live longer? What makes a stock's price go up? Why did you get the flu? Causal questions like these arise on a regular basis, but most people likely have not thought deeply about how to answer them.This book helps you think about causality in a structured way: What is a cause, what are causes good for, and what is compelling evidence of causality? Author Samantha Kleinberg shows you how to develop a set of tools for thinking more critically about causes. You'll learn how to question claims, identify causes, make decisions based on causal information, and verify causes through further tests.Whether it's figuring out what data you need, or understanding that the way you collect and prepare data affects the conclusions you can draw from it, Why will help you sharpen your causal inference skills.},
  language = {English},
  publisher = {{O'Reilly Media}},
  author = {Samantha Kleinberg},
  month = {dec},
  year = {2015},
}

@Book{kleinbergWhyGuideFinding2015,
  address = {{Beijing ; Boston}},
  edition = {1 edition},
  title = {Why: {{A Guide}} to {{Finding}} and {{Using Causes}}},
  isbn = {978-1-4919-4964-1},
  shorttitle = {Why},
  abstract = {Can drinking coffee help people live longer? What makes a stock's price go up? Why did you get the flu? Causal questions like these arise on a regular basis, but most people likely have not thought deeply about how to answer them.This book helps you think about causality in a structured way: What is a cause, what are causes good for, and what is compelling evidence of causality? Author Samantha Kleinberg shows you how to develop a set of tools for thinking more critically about causes. You'll learn how to question claims, identify causes, make decisions based on causal information, and verify causes through further tests.Whether it's figuring out what data you need, or understanding that the way you collect and prepare data affects the conclusions you can draw from it, Why will help you sharpen your causal inference skills.},
  language = {English},
  publisher = {{O'Reilly Media}},
  author = {Samantha Kleinberg},
  month = {dec},
  year = {2015},
}
@Article{pearlCausalInferenceStatistics2009,
  title = {Causal Inference in Statistics: {{An}} Overview},
  volume = {3},
  issn = {1935-7516},
  shorttitle = {Causal Inference in Statistics},
  language = {en},
  number = {0},
  journal = {Statistics Surveys},
  doi = {10.1214/09-SS057},
  author = {Judea Pearl},
  year = {2009},
  pages = {96-146},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/ZEYMJ5KY/Pearl - 2009 - Causal inference in statistics An overview.pdf},
}
@Book{kleinbergCausalityProbabilityTime2018,
  title = {Causality, Probability, and Time},
  isbn = {978-1-107-68601-4 978-1-107-02648-3},
  language = {English},
  author = {Samantha Kleinberg},
  year = {2018},
  note = {OCLC: 1039151752},
}

@Article{hernanCWordScientificEuphemisms2018,
  title = {The {{C}}-{{Word}}: {{Scientific Euphemisms Do Not Improve Causal Inference From Observational Data}}},
  volume = {108},
  issn = {0090-0036, 1541-0048},
  shorttitle = {The {{C}}-{{Word}}},
  language = {en},
  number = {5},
  journal = {American Journal of Public Health},
  doi = {10.2105/AJPH.2018.304337},
  author = {Miguel A. Hernán},
  month = {may},
  year = {2018},
  pages = {616-619},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/28367YFR/Hernán - 2018 - The C-Word Scientific Euphemisms Do Not Improve C.pdf},
}
@Article{beckExplanationPredictionCausality,
  title = {Explanation, Prediction, and Causality: {{Three}} Sides of the Same Coin?},
  abstract = {In this essay we make four interrelated points. First, we reiterate previous arguments (Kleinberg et al 2015) that forecasting problems are more common in social science than is often appreciated. From this observation it follows that social scientists should care about predictive accuracy in addition to unbiased or consistent estimation of causal relationships. Second, we argue that social scientists should be interested in prediction even if they have no interest in forecasting per se. Whether they do so explicitly or not, that is, causal claims necessarily make predictions; thus it is both fair and arguably useful to hold them accountable for the accuracy of the predictions they make. Third, we argue that prediction, used in either of the above two senses, is a useful metric for quantifying progress. Important differences between social science explanations and machine learning algorithms notwithstanding, social scientists can still learn from approaches like the Common Task Framework (CTF) which have successfully driven progress in certain fields of AI over the past 30 years (Donoho, 2015). Finally, we anticipate that as the predictive performance of forecasting models and explanations alike receives more attention, it will become clear that it is subject to some upper limit which lies well below deterministic accuracy for many applications of interest (Martin et al 2016). Characterizing the properties of complex social systems that lead to higher or lower predictive limits therefore poses an interesting challenge for computational social science.},
  language = {en},
  author = {Emorie Beck and Jake Bowers and Tony Grubesic},
  pages = {14},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/EPBYESLV/Beck et al. - Explanation, prediction, and causality Three side.pdf},
}

@Article{saddikiPrimerCausalityData2018,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1809.02408},
  primaryclass = {stat},
  title = {A {{Primer}} on {{Causality}} in {{Data Science}}},
  abstract = {Many questions in Data Science are fundamentally causal in that our objective is to learn the effect of some exposure, randomized or not, on an outcome interest. Even studies that are seemingly non-causal, such as those with the goal of prediction or prevalence estimation, have causal elements, including differential censoring or measurement. As a result, we, as Data Scientists, need to consider the underlying causal mechanisms that gave rise to the data, rather than simply the pattern or association observed in those data. In this work, we review the 'Causal Roadmap' of Petersen and van der Laan (2014) to provide an introduction to some key concepts in causal inference. Similar to other causal frameworks, the steps of the Roadmap include clearly stating the scientific question, defining of the causal model, translating the scientific question into a causal parameter, assessing the assumptions needed to express the causal parameter as a statistical estimand, implementation of statistical estimators including parametric and semi-parametric methods, and interpretation of our findings. We believe that using such a framework in Data Science will help to ensure that our statistical analyses are guided by the scientific question driving our research, while avoiding over-interpreting our results. We focus on the effect of an exposure occurring at a single time point and highlight the use of targeted maximum likelihood estimation (TMLE) with Super Learner.},
  journal = {arXiv:1809.02408 [stat]},
  author = {Hachem Saddiki and Laura B. Balzer},
  month = {sep},
  year = {2018},
  keywords = {Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/C9PLSI7W/Saddiki and Balzer - 2018 - A Primer on Causality in Data Science.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/N6ESV2CR/1809.html},
}
@Article{wattsExplanationPredictionCausality2018,
  title = {Explanation, Prediction, and Causality: {{Three}} Sides of the Same Coin?},
  shorttitle = {Explanation, Prediction, and Causality},
  abstract = {In this essay we make four interrelated points. First, we reiterate previous arguments (Kleinberg et al 2015) that forecasting problems are more common in social science than is often appreciated. From this observation it follows that social scientists should care about predictive accuracy in addition to unbiased or consistent estimation of causal relationships. Second, we argue that social scientists should be interested in prediction even if they have no interest in forecasting per se. Whether they do so explicitly or not, that is, causal claims necessarily make predictions; thus it is both fair and arguably useful to hold them accountable for the accuracy of the predictions they make. Third, we argue that prediction, used in either of the above two senses, is a useful metric for quantifying progress. Important differences between social science explanations and machine learning algorithms notwithstanding, social scientists can still learn from approaches like the Common Task Framework (CTF) which have successfully driven progress in certain fields of AI over the past 30 years (Donoho, 2015). Finally, we anticipate that as the predictive performance of forecasting models and explanations alike receives more attention, it will become clear that it is subject to some upper limit which lies well below deterministic accuracy for many applications of interest (Martin et al 2016). Characterizing the properties of complex social systems that lead to higher or lower predictive limits therefore poses an interesting challenge for computational social science.},
  doi = {10.31219/osf.io/u6vz5},
  author = {Duncan J Watts and Emorie D Beck and Elisa Jayne Bienenstock and Jake Bowers and Aaron Frank and Anthony Grubesic and Jake Hofman and Julia Marie Rohrer and Matthew Salganik},
  month = {oct},
  year = {2018},
}
@Article{kleinbergTheoryPredictiveIt2017,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1706.06974},
  primaryclass = {cs, stat},
  title = {The {{Theory}} Is {{Predictive}}, but Is It {{Complete}}? {{An Application}} to {{Human Perception}} of {{Randomness}}},
  shorttitle = {The {{Theory}} Is {{Predictive}}, but Is It {{Complete}}?},
  abstract = {When we test a theory using data, it is common to focus on correctness: do the predictions of the theory match what we see in the data? But we also care about completeness: how much of the predictable variation in the data is captured by the theory? This question is difficult to answer, because in general we do not know how much {"}predictable variation{"} there is in the problem. In this paper, we consider approaches motivated by machine learning algorithms as a means of constructing a benchmark for the best attainable level of prediction. We illustrate our methods on the task of predicting human-generated random sequences. Relative to an atheoretical machine learning algorithm benchmark, we find that existing behavioral models explain roughly 15 percent of the predictable variation in this problem. This fraction is robust across several variations on the problem. We also consider a version of this approach for analyzing field data from domains in which human perception and generation of randomness has been used as a conceptual framework; these include sequential decision-making and repeated zero-sum games. In these domains, our framework for testing the completeness of theories provides a way of assessing their effectiveness over different contexts; we find that despite some differences, the existing theories are fairly stable across our field domains in their performance relative to the benchmark. Overall, our results indicate that (i) there is a significant amount of structure in this problem that existing models have yet to capture and (ii) there are rich domains in which machine learning may provide a viable approach to testing completeness.},
  journal = {arXiv:1706.06974 [cs, stat]},
  author = {Jon Kleinberg and Annie Liang and Sendhil Mullainathan},
  month = {jun},
  year = {2017},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/HUXR25FG/Kleinberg et al. - 2017 - The Theory is Predictive, but is it Complete An A.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/RBATG98V/1706.html},
}
@Book{kuhnFeatureEngineeringSelection2019,
  address = {{Milton}},
  title = {Feature {{Engineering}} and {{Selection}}: A {{Practical Approach}} for {{Predictive Models}}.},
  isbn = {978-1-351-60947-0 978-1-315-10823-0 978-1-351-60945-6 978-1-351-60946-3},
  shorttitle = {Feature {{Engineering}} and {{Selection}}},
  abstract = {The process of developing predictive models includes many stages. Most resources focus on the modeling algorithms but neglect other critical aspects of the modeling process. This book describes techniques for finding the best representations of predictors for modeling and for nding the best subset of predictors for improving model performance. A variety of example data sets are used to illustrate the techniques along with R programs for reproducing the results.},
  language = {English},
  publisher = {{CRC Press LLC}},
  author = {Max Kuhn and Kjell Johnson},
  year = {2019},
  note = {OCLC: 1111432732},
}
@Article{friedmanRegularizationPathsGeneralized2010,
  title = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  volume = {33},
  number = {1},
  journal = {Journal of Statistical Software},
  author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
  year = {2010},
  pages = {1-22},
}
@Book{kuhnCaretClassificationRegression2018,
  title = {Caret: {{Classification}} and {{Regression Training}}},
  author = {Max Kuhn and Jed Wing and Steve Weston and Andre Williams and Chris Keefer and Allan Engelhardt and Tony Cooper and Zachary Mayer and Brenton Kenkel and the R. Core Team and Michael Benesty and Reynald Lescarbeau and Andrew Ziem and Luca Scrucca and Yuan Tang and Can Candan},
  year = {2018},
}

@Book{kuhnCaretClassificationRegression2018,
  title = {Caret: {{Classification}} and {{Regression Training}}},
  author = {Max Kuhn and Jed Wing and Steve Weston and Andre Williams and Chris Keefer and Allan Engelhardt and Tony Cooper and Zachary Mayer and Brenton Kenkel and the R. Core Team and Michael Benesty and Reynald Lescarbeau and Andrew Ziem and Luca Scrucca and Yuan Tang and Can Candan},
  year = {2018},
}
@Book{angristMasteringMetricsPath2015,
  address = {{Princeton ; Oxford}},
  title = {Mastering 'metrics: The Path from Cause to Effect},
  isbn = {978-0-691-15283-7 978-0-691-15284-4},
  lccn = {HB139 .A53984 2015},
  shorttitle = {Mastering 'metrics},
  abstract = {{"}Applied econometrics, known to aficionados as 'metrics, is the original data science. 'Metrics encompasses the statistical methods economists use to untangle cause and effect in human affairs. Through accessible discussion and with a dose of kung fu-themed humor, Mastering 'Metrics presents the essential tools of econometric research and demonstrates why econometrics is exciting and useful.The five most valuable econometric methods, or what the authors call the Furious Five--random assignment, regression, instrumental variables, regression discontinuity designs, and differences in differences--are illustrated through well-crafted real-world examples (vetted for awesomeness by Kung Fu Panda's Jade Palace). Does health insurance make you healthier? Randomized experiments provide answers. Are expensive private colleges and selective public high schools better than more pedestrian institutions? Regression analysis and a regression discontinuity design reveal the surprising truth. When private banks teeter, and depositors take their money and run, should central banks step in to save them? Differences-in-differences analysis of a Depression-era banking crisis offers a response. Could arresting O. J. Simpson have saved his ex-wife's life? Instrumental variables methods instruct law enforcement authorities in how best to respond to domestic abuse.Wielding econometric tools with skill and confidence, Mastering 'Metrics uses data and statistics to illuminate the path from cause to effect. Shows why econometrics is important Explains econometric research through humorous and accessible discussion Outlines empirical methods central to modern econometric practice Works through interesting and relevant real-world examples {"}--},
  publisher = {{Princeton University Press}},
  author = {Joshua David Angrist and J{\"o}rn-Steffen Pischke},
  year = {2015},
  keywords = {BUSINESS \& ECONOMICS / Econometrics,Econometrics},
}

@Article{gelmanCausalityStatisticalLearning2011,
  title = {Causality and {{Statistical Learning}}.},
  volume = {117},
  issn = {0002-9602, 1537-5390},
  shorttitle = {Causality and {{Statistical Learning}} {{{\emph{Counterfactuals}}}}{\emph{ and }}{{{\emph{Causal Inference}}}}},
  language = {en},
  number = {3},
  journal = {American Journal of Sociology},
  doi = {10.1086/662659},
  author = {Andrew Gelman},
  month = {nov},
  year = {2011},
  pages = {955-966},
}
@Article{shrierReducingBiasDirected2008,
  title = {Reducing Bias through Directed Acyclic Graphs},
  volume = {8},
  issn = {1471-2288},
  abstract = {Background: The objective of most biomedical research is to determine an unbiased estimate of effect for an exposure on an outcome, i.e. to make causal inferences about the exposure. Recent developments in epidemiology have shown that traditional methods of identifying confounding and adjusting for confounding may be inadequate.},
  language = {en},
  number = {1},
  journal = {BMC Medical Research Methodology},
  doi = {10.1186/1471-2288-8-70},
  author = {Ian Shrier and Robert W Platt},
  month = {dec},
  year = {2008},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/MZYP5HTZ/Shrier and Platt - 2008 - Reducing bias through directed acyclic graphs.pdf},
}

@Article{shrierReducingBiasDirected2008,
  title = {Reducing Bias through Directed Acyclic Graphs},
  volume = {8},
  issn = {1471-2288},
  abstract = {Background: The objective of most biomedical research is to determine an unbiased estimate of effect for an exposure on an outcome, i.e. to make causal inferences about the exposure. Recent developments in epidemiology have shown that traditional methods of identifying confounding and adjusting for confounding may be inadequate.},
  language = {en},
  number = {1},
  journal = {BMC Medical Research Methodology},
  doi = {10.1186/1471-2288-8-70},
  author = {Ian Shrier and Robert W Platt},
  month = {dec},
  year = {2008},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/UPXC3XLX/Shrier and Platt - 2008 - Reducing bias through directed acyclic graphs.pdf},
}
@Article{heckstedenIndividualResponseExercise2015,
  title = {Individual Response to Exercise Training - a Statistical Perspective},
  volume = {118},
  issn = {8750-7587, 1522-1601},
  language = {en},
  number = {12},
  journal = {Journal of Applied Physiology},
  doi = {10.1152/japplphysiol.00714.2014},
  author = {Anne Hecksteden and Jochen Kraushaar and Friederike Scharhag-Rosenberger and Daniel Theisen and Stephen Senn and Tim Meyer},
  month = {jun},
  year = {2015},
  pages = {1450-1459},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/84LY3A65/Hecksteden et al. - 2015 - Individual response to exercise training - a stati.pdf},
}

@Article{heckstedenRepeatedTestingAssessment2018,
  title = {Repeated Testing for the Assessment of Individual Response to Exercise Training},
  volume = {124},
  issn = {8750-7587},
  abstract = {Observed response to regular exercise training differs widely between individuals even in tightly controlled research settings. However, the respective contributions of random error and true interindividual differences as well as the relative frequency of nonresponders are disputed. Specific challenges of analyses on the individual level as well as a striking heterogeneity in definitions may partly explain these inconsistent results. Repeated testing during the training phase specifically addresses the requirements of analyses on the individual level. Here we report a first implementation of this innovative design amendment in a head-to-head comparison of existing analytical approaches. To allow for comparative implementation of approaches we conducted a controlled endurance training trial (1 yr walking/jogging, 3 days/wk for 45 min with 60\% heart rate reserve) in healthy, untrained subjects (n = 36, age\,=\,46\,{$\pm$}\,8 yr; body mass index 24.7\,{$\pm$}\,2.7 kg/m2; V\.o2max 36.6\,{$\pm$}\,5.4). In the training group additional V\.o2max tests were conducted after 3, 6, and 9 mo. Duration of the control condition was 6 mo due to ethical constraints. General efficacy of the training intervention could be verified by a significant increase in V\.o2max in the training group (P {$<$} 0.001 vs. control). Individual training response of relevant magnitude ({$>$}0.2 \texttimes{} baseline variability in V\.o2max) could be demonstrated by several approaches. Regarding the classification of individuals, only 11 of 20 subjects were consistently classified, demonstrating remarkable disagreement between approaches. These results are in support of relevant interindividual variability in training efficacy and stress the limitations of a responder classification. Moreover, this proof-of-concept underlines the need for tailored methodological approaches for well-defined problems.NEW \& NOTEWORTHY This work reports a first implementation of a repeated testing training trial for the investigation of individual response. This design amendment was recently proposed to address specifically the statistical requirements of analyses on the individual level. Moreover, a comprehensive comparison of previously published methods exemplifies the striking heterogeneity of existing approaches.},
  number = {6},
  journal = {Journal of Applied Physiology},
  doi = {10.1152/japplphysiol.00896.2017},
  author = {Anne Hecksteden and Werner Pitsch and Friederike Rosenberger and Tim Meyer},
  month = {jan},
  year = {2018},
  pages = {1567-1579},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/G6TTG8GX/japplphysiol.00896.html},
}

@Article{heckstedenRepeatedTestingAssessment2018,
  title = {Repeated Testing for the Assessment of Individual Response to Exercise Training},
  volume = {124},
  issn = {8750-7587},
  abstract = {Observed response to regular exercise training differs widely between individuals even in tightly controlled research settings. However, the respective contributions of random error and true interindividual differences as well as the relative frequency of nonresponders are disputed. Specific challenges of analyses on the individual level as well as a striking heterogeneity in definitions may partly explain these inconsistent results. Repeated testing during the training phase specifically addresses the requirements of analyses on the individual level. Here we report a first implementation of this innovative design amendment in a head-to-head comparison of existing analytical approaches. To allow for comparative implementation of approaches we conducted a controlled endurance training trial (1 yr walking/jogging, 3 days/wk for 45 min with 60\% heart rate reserve) in healthy, untrained subjects (n = 36, age\,=\,46\,{$\pm$}\,8 yr; body mass index 24.7\,{$\pm$}\,2.7 kg/m2; V\.o2max 36.6\,{$\pm$}\,5.4). In the training group additional V\.o2max tests were conducted after 3, 6, and 9 mo. Duration of the control condition was 6 mo due to ethical constraints. General efficacy of the training intervention could be verified by a significant increase in V\.o2max in the training group (P {$<$} 0.001 vs. control). Individual training response of relevant magnitude ({$>$}0.2 \texttimes{} baseline variability in V\.o2max) could be demonstrated by several approaches. Regarding the classification of individuals, only 11 of 20 subjects were consistently classified, demonstrating remarkable disagreement between approaches. These results are in support of relevant interindividual variability in training efficacy and stress the limitations of a responder classification. Moreover, this proof-of-concept underlines the need for tailored methodological approaches for well-defined problems.NEW \& NOTEWORTHY This work reports a first implementation of a repeated testing training trial for the investigation of individual response. This design amendment was recently proposed to address specifically the statistical requirements of analyses on the individual level. Moreover, a comprehensive comparison of previously published methods exemplifies the striking heterogeneity of existing approaches.},
  number = {6},
  journal = {Journal of Applied Physiology},
  doi = {10.1152/japplphysiol.00896.2017},
  author = {Anne Hecksteden and Werner Pitsch and Friederike Rosenberger and Tim Meyer},
  month = {jan},
  year = {2018},
  pages = {1567-1579},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/YABTUBB6/japplphysiol.00896.html},
}

@Article{heckstedenIndividualResponseExercise2015,
  title = {Individual Response to Exercise Training - a Statistical Perspective},
  volume = {118},
  issn = {8750-7587, 1522-1601},
  language = {en},
  number = {12},
  journal = {Journal of Applied Physiology},
  doi = {10.1152/japplphysiol.00714.2014},
  author = {Anne Hecksteden and Jochen Kraushaar and Friederike Scharhag-Rosenberger and Daniel Theisen and Stephen Senn and Tim Meyer},
  month = {jun},
  year = {2015},
  pages = {1450-1459},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/JQMMWW4U/Hecksteden et al. - 2015 - Individual response to exercise training - a stati.pdf},
}
@Article{normanRelationDistributionAnchorBased2001,
  title = {Relation of {{Distribution}}- and {{Anchor}}-{{Based Approaches}} in {{Interpretation}} of {{Changes}} in {{Health}}-{{Related Quality}} of {{Life}}:},
  volume = {39},
  issn = {0025-7079},
  shorttitle = {Relation of {{Distribution}}- and {{Anchor}}-{{Based Approaches}} in {{Interpretation}} of {{Changes}} in {{Health}}-{{Related Quality}} of {{Life}}},
  language = {en},
  number = {10},
  journal = {Medical Care},
  doi = {10.1097/00005650-200110000-00002},
  author = {Geoffrey R. Norman and Femida {Gwadry Sridhar} and Gordon H. Guyatt and Stephen D. Walter},
  month = {oct},
  year = {2001},
  pages = {1039-1047},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/KFY67MRK/Norman et al. - 2001 - Relation of Distribution- and Anchor-Based Approac.pdf},
}
@Article{estradaStatisticsEvaluatingPrepost2019,
  title = {Statistics for {{Evaluating Pre}}-Post {{Change}}: {{Relation Between Change}} in the {{Distribution Center}} and {{Change}} in the {{Individual Scores}}},
  volume = {9},
  issn = {1664-1078},
  shorttitle = {Statistics for {{Evaluating Pre}}-Post {{Change}}},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2018.02696},
  author = {Eduardo Estrada and Emilio Ferrer and Antonio Pardo},
  month = {jan},
  year = {2019},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/GUY7BWHR/Estrada et al. - 2019 - Statistics for Evaluating Pre-post Change Relatio.pdf},
}
@Article{hernanDoesObesityShorten2008,
  title = {Does Obesity Shorten Life? {{The}} Importance of Well-Defined Interventions to Answer Causal Questions},
  volume = {32},
  issn = {0307-0565, 1476-5497},
  shorttitle = {Does Obesity Shorten Life?},
  language = {en},
  number = {S3},
  journal = {International Journal of Obesity},
  doi = {10.1038/ijo.2008.82},
  author = {M A Hernán and S L Taubman},
  month = {aug},
  year = {2008},
  pages = {S8-S14},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/47WRJZZU/ijo200882.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/UW9C3E4Y/Hernán and Taubman - 2008 - Does obesity shorten life The importance of well-.pdf},
}
@Article{zhaoCausalInterpretationsBlackBox2019,
  title = {Causal {{Interpretations}} of {{Black}}-{{Box Models}}},
  issn = {0735-0015, 1537-2707},
  language = {en},
  journal = {Journal of Business \& Economic Statistics},
  doi = {10.1080/07350015.2019.1624293},
  author = {Qingyuan Zhao and Trevor Hastie},
  month = {jul},
  year = {2019},
  pages = {1-10},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/ZZD9UTW2/Zhao and Hastie - 2019 - Causal Interpretations of Black-Box Models.pdf},
}
@Article{hernanCausalKnowledgePrerequisite2002,
  title = {Causal {{Knowledge}} as a {{Prerequisite}} for {{Confounding Evaluation}}: {{An Application}} to {{Birth Defects Epidemiology}}},
  volume = {155},
  issn = {00029262},
  shorttitle = {Causal {{Knowledge}} as a {{Prerequisite}} for {{Confounding Evaluation}}},
  number = {2},
  journal = {American Journal of Epidemiology},
  doi = {10.1093/aje/155.2.176},
  author = {M. A. Hernan},
  month = {jan},
  year = {2002},
  pages = {176-184},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/9FERGCI8/Hernan - 2002 - Causal Knowledge as a Prerequisite for Confounding.pdf},
}
@Article{glazierChallengingConventionalParadigms2018,
  title = {Challenging {{Conventional Paradigms}} in {{Applied Sports Biomechanics Research}}},
  issn = {0112-1642, 1179-2035},
  abstract = {This paper evaluates the effectiveness of, and highlights issues with, conventional paradigms in applied sports biomechanics research and comments on their capacity to optimise techniques of individual athletes. In empirical studies, group-based analyses often mask variability between athletes and only permit probabilistic `in general' or `on average' statements that may not be applicable to specific athletes. In individual-based analyses, performance parameters typically exhibit a small range and a flat response over iterative performance trials, making establishing associations between performance parameters and the performance criterion problematic. In theoretical studies, computer simulation modelling putatively enables athlete-specific optimum techniques to be identified, but given each athlete's unique intrinsic dynamics, it is far from certain that these optimum techniques will be attainable, particularly under the often intense psychological pressures of competition, irrespective of the volume of practice undertaken. Sports biomechanists and coaching practitioners are advised to be more circumspect with regard to interpreting the results of applied sports biomechanics research and have greater awareness of their assumptions and limitations, as inappropriate interpretation of results may have adverse consequences for performance and injury.},
  language = {en},
  journal = {Sports Medicine},
  doi = {10.1007/s40279-018-1030-1},
  author = {Paul S. Glazier and Sina Mehdizadeh},
  month = {dec},
  year = {2018},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/83TMN2ZA/Glazier and Mehdizadeh - 2018 - Challenging Conventional Paradigms in Applied Spor.pdf},
}

@Article{molenaarNewPersonSpecificParadigm2009,
  title = {The {{New Person}}-{{Specific Paradigm}} in {{Psychology}}},
  volume = {18},
  issn = {0963-7214, 1467-8721},
  abstract = {Most research methodology in the behavioral sciences employs interindividual analyses, which provide information about the state of affairs of the population. However, as shown by classical mathematical-statistical theorems (the ergodic theorems), such analyses do not provide information for, and cannot be applied at, the level of the individual, except on rare occasions when the processes of interest meet certain stringent conditions. When psychological processes violate these conditions, the interindividual analyses that are now standardly applied have to be replaced by analysis of intraindividual variation in order to obtain valid results. Two illustrations involving analysis of intraindividual variation of personality and emotional processes are given.},
  language = {en},
  number = {2},
  journal = {Current Directions in Psychological Science},
  doi = {10.1111/j.1467-8721.2009.01619.x},
  author = {Peter C.M. Molenaar and Cynthia G. Campbell},
  month = {apr},
  year = {2009},
  pages = {112-117},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/IGWJV8T4/Molenaar and Campbell - 2009 - The New Person-Specific Paradigm in Psychology.pdf},
}

@Article{molenaarManifestoPsychologyIdiographic2004,
  title = {A {{Manifesto}} on {{Psychology}} as {{Idiographic Science}}: {{Bringing}} the {{Person Back Into Scientific Psychology}}, {{This Time Forever}}},
  volume = {2},
  issn = {1536-6367, 1536-6359},
  shorttitle = {A {{Manifesto}} on {{Psychology}} as {{Idiographic Science}}},
  abstract = {Psychology is focused on variation between cases (interindividual variation). Results thus obtained are considered to be generalizable to the understanding and explanation of variation within single cases (intraindividual variation). It is indicated, however, that the direct consequences of the classical ergodic theorems for psychology and psychometdcs invalidate this conjectured generalizability: only under very strict conditions\textemdash{}which are hardly obtained in real psychological processes-can a generalization be made from a structure of interindividual variation to the analogous structure of intraindividual variation. Illustrations of the lack of this generalizability are given in the contexts of psychometrics, developmental psychology, and personality theory.},
  language = {en},
  number = {4},
  journal = {Measurement: Interdisciplinary Research \& Perspective},
  doi = {10.1207/s15366359mea0204_1},
  author = {Peter C. M. Molenaar},
  month = {oct},
  year = {2004},
  pages = {201-218},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/N6JZ555S/Molenaar - 2004 - A Manifesto on Psychology as Idiographic Science .pdf},
}

@Article{glazierChallengingConventionalParadigms2018,
  title = {Challenging {{Conventional Paradigms}} in {{Applied Sports Biomechanics Research}}},
  issn = {0112-1642, 1179-2035},
  abstract = {This paper evaluates the effectiveness of, and highlights issues with, conventional paradigms in applied sports biomechanics research and comments on their capacity to optimise techniques of individual athletes. In empirical studies, group-based analyses often mask variability between athletes and only permit probabilistic `in general' or `on average' statements that may not be applicable to specific athletes. In individual-based analyses, performance parameters typically exhibit a small range and a flat response over iterative performance trials, making establishing associations between performance parameters and the performance criterion problematic. In theoretical studies, computer simulation modelling putatively enables athlete-specific optimum techniques to be identified, but given each athlete's unique intrinsic dynamics, it is far from certain that these optimum techniques will be attainable, particularly under the often intense psychological pressures of competition, irrespective of the volume of practice undertaken. Sports biomechanists and coaching practitioners are advised to be more circumspect with regard to interpreting the results of applied sports biomechanics research and have greater awareness of their assumptions and limitations, as inappropriate interpretation of results may have adverse consequences for performance and injury.},
  language = {en},
  journal = {Sports Medicine},
  doi = {10.1007/s40279-018-1030-1},
  author = {Paul S. Glazier and Sina Mehdizadeh},
  month = {dec},
  year = {2018},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/R4Q9NNWI/Glazier and Mehdizadeh - 2018 - Challenging Conventional Paradigms in Applied Spor.pdf},
}

@Article{heckmanRejoinderResponseSobel2005,
  title = {Rejoinder: {{Response}} to {{Sobel}}},
  volume = {35},
  issn = {0081-1750, 1467-9531},
  shorttitle = {Rejoinder},
  language = {en},
  number = {1},
  journal = {Sociological Methodology},
  doi = {10.1111/j.0081-1750.2006.00166.x},
  author = {James J. Heckman},
  month = {aug},
  year = {2005},
  pages = {135-150},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/V3ZTE8KL/Heckman - 2005 - Rejoinder Response to Sobel.pdf},
}

@Article{goldsteinPeekingBlackBox2013,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1309.6392},
  primaryclass = {stat},
  title = {Peeking {{Inside}} the {{Black Box}}: {{Visualizing Statistical Learning}} with {{Plots}} of {{Individual Conditional Expectation}}},
  shorttitle = {Peeking {{Inside}} the {{Black Box}}},
  abstract = {This article presents Individual Conditional Expectation (ICE) plots, a tool for visualizing the model estimated by any supervised learning algorithm. Classical partial dependence plots (PDPs) help visualize the average partial relationship between the predicted response and one or more features. In the presence of substantial interaction effects, the partial response relationship can be heterogeneous. Thus, an average curve, such as the PDP, can obfuscate the complexity of the modeled relationship. Accordingly, ICE plots refine the partial dependence plot by graphing the functional relationship between the predicted response and the feature for individual observations. Specifically, ICE plots highlight the variation in the fitted values across the range of a covariate, suggesting where and to what extent heterogeneities might exist. In addition to providing a plotting suite for exploratory analysis, we include a visual test for additive structure in the data generating model. Through simulated examples and real data sets, we demonstrate how ICE plots can shed light on estimated models in ways PDPs cannot. Procedures outlined are available in the R package ICEbox.},
  journal = {arXiv:1309.6392 [stat]},
  author = {Alex Goldstein and Adam Kapelner and Justin Bleich and Emil Pitkin},
  month = {sep},
  year = {2013},
  keywords = {Statistics - Applications},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/QEAJDLE7/Goldstein et al. - 2013 - Peeking Inside the Black Box Visualizing Statisti.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/Q6VTJVLZ/1309.html},
}


@Article{hernanInvitedCommentaryCausal2009,
  title = {Invited {{Commentary}}: {{Causal Diagrams}} and {{Measurement Bias}}},
  volume = {170},
  issn = {0002-9262, 1476-6256},
  shorttitle = {Invited {{Commentary}}},
  language = {en},
  number = {8},
  journal = {American Journal of Epidemiology},
  doi = {10.1093/aje/kwp293},
  author = {M. A. Hernan and S. R. Cole},
  month = {oct},
  year = {2009},
  pages = {959-962},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/HTT5MEGV/Hernan and Cole - 2009 - Invited Commentary Causal Diagrams and Measuremen.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/JDDEGVIF/Hernan and Cole - 2009 - Invited Commentary Causal Diagrams and Measuremen.pdf},
  ids = {hernanInvitedCommentaryCausal2009a},
}
@Article{novickAxiomsPrincipalResults1966,
  title = {The Axioms and Principal Results of Classical Test Theory},
  volume = {3},
  issn = {00222496},
  language = {en},
  number = {1},
  journal = {Journal of Mathematical Psychology},
  doi = {10.1016/0022-2496(66)90002-2},
  author = {Melvin R. Novick},
  month = {feb},
  year = {1966},
  pages = {1-18},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/HSNB2ZJX/Novick - 1966 - The axioms and principal results of classical test.pdf},
}

@Book{allenIntroductionMeasurementTheory2001,
  address = {{Long Grove, Ill}},
  edition = {1 edition},
  title = {Introduction to {{Measurement Theory}}},
  isbn = {978-1-57766-230-3},
  abstract = {Introduction to Measurement Theory bridges the gap between texts that offer a mathematically rigorous treatment of the statistical properties of measurement and ones that discuss the topic in a basic, {"}cookbook{"} fashion. Without overwhelming novices or boring the more mathematically sophisticated, the authors effectively cover the construction of psychological tests and the interpretation of test scores and scales; critically examine classical true-score theory; and explain theoretical assumptions and modern measurement models, controversies, and developments. Practical applications, examples, and study questions facilitate a better understanding of the uses and limitations of common measures of test reliability and validity and how to perform the basic item analysis necessary for test construction.},
  language = {English},
  publisher = {{Waveland Pr Inc}},
  author = {Mary J. Allen and Wendy M. Yen},
  month = {dec},
  year = {2001},
}

@Article{novickAxiomsPrincipalResults1966,
  title = {The Axioms and Principal Results of Classical Test Theory},
  volume = {3},
  issn = {00222496},
  language = {en},
  number = {1},
  journal = {Journal of Mathematical Psychology},
  doi = {10.1016/0022-2496(66)90002-2},
  author = {Melvin R. Novick},
  month = {feb},
  year = {1966},
  pages = {1-18},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/SBZLPUZS/Novick - 1966 - The axioms and principal results of classical test.pdf},
}

@Book{allenIntroductionMeasurementTheory2001,
  address = {{Long Grove, Ill}},
  edition = {1 edition},
  title = {Introduction to {{Measurement Theory}}},
  isbn = {978-1-57766-230-3},
  abstract = {Introduction to Measurement Theory bridges the gap between texts that offer a mathematically rigorous treatment of the statistical properties of measurement and ones that discuss the topic in a basic, {"}cookbook{"} fashion. Without overwhelming novices or boring the more mathematically sophisticated, the authors effectively cover the construction of psychological tests and the interpretation of test scores and scales; critically examine classical true-score theory; and explain theoretical assumptions and modern measurement models, controversies, and developments. Practical applications, examples, and study questions facilitate a better understanding of the uses and limitations of common measures of test reliability and validity and how to perform the basic item analysis necessary for test construction.},
  language = {English},
  publisher = {{Waveland Pr Inc}},
  author = {Mary J. Allen and Wendy M. Yen},
  month = {dec},
  year = {2001},
}
@Misc{hopkinsBiasBlandAltmanNot2004,
  title = {Bias in {{Bland}}-{{Altman}} but Not {{Regression Validity Analyses}}},
  abstract = {An instrument that has been calibrated against a criterion measure with a sample of subjects is sometimes checked against the criterion in a validity study with another sample.  In a spreadsheet-based simulation of such calibration and validity studies, a Bland-Altman plot of difference vs mean values for the instrument and criterion shows a systematic proportional bias in the instrument's readings, even though none is present.  This artifactual bias arises in a Bland-Altman plot of any measures with substantial random error. In contrast, a regression analysis of the criterion vs the instrument shows no bias.  The regression analysis also provides complete statistics for recalibrating the instrument, if bias develops or if random error changes since the last calibration.  The Bland-Altman analysis of validity should therefore be abandoned in favor of regression.

KEYWORDS: calibration, method comparison, random error, systematic error, standard error of the estimate.},
  journal = {Sportscience.org},
  howpublished = {https://sportsci.org/jour/04/wghbias.htm},
  author = {Will G Hopkins},
  year = {2004},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/TS3BC7F6/wghbias.html},
  note = {Sportscience 8, 42-46, 2004 (sportsci.org/jour/04/wghbias.htm)},
}

@Misc{hopkinsBiasBlandAltmanNot2004,
  title = {Bias in {{Bland}}-{{Altman}} but Not {{Regression Validity Analyses}}},
  abstract = {An instrument that has been calibrated against a criterion measure with a sample of subjects is sometimes checked against the criterion in a validity study with another sample.  In a spreadsheet-based simulation of such calibration and validity studies, a Bland-Altman plot of difference vs mean values for the instrument and criterion shows a systematic proportional bias in the instrument's readings, even though none is present.  This artifactual bias arises in a Bland-Altman plot of any measures with substantial random error. In contrast, a regression analysis of the criterion vs the instrument shows no bias.  The regression analysis also provides complete statistics for recalibrating the instrument, if bias develops or if random error changes since the last calibration.  The Bland-Altman analysis of validity should therefore be abandoned in favor of regression.

KEYWORDS: calibration, method comparison, random error, systematic error, standard error of the estimate.},
  journal = {Sportscience.org},
  howpublished = {https://sportsci.org/jour/04/wghbias.htm},
  author = {Will G Hopkins},
  year = {2004},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/6TZWQBNK/wghbias.html},
  note = {Sportscience 8, 42-46, 2004 (sportsci.org/jour/04/wghbias.htm)},
}
@Article{ohaganDicingUnknown2004,
  title = {Dicing with the Unknown},
  volume = {1},
  issn = {17409705},
  language = {en},
  number = {3},
  journal = {Significance},
  doi = {10.1111/j.1740-9713.2004.00050.x},
  author = {Tony O'Hagan},
  month = {sep},
  year = {2004},
  pages = {132-133},
}
@Book{dienesUnderstandingPsychologyScience2008,
  address = {{New York}},
  edition = {2008 edition},
  title = {Understanding {{Psychology}} as a {{Science}}: {{An Introduction}} to {{Scientific}} and {{Statistical Inference}}},
  isbn = {978-0-230-54231-0},
  shorttitle = {Understanding {{Psychology}} as a {{Science}}},
  abstract = {How can we objectively define categories of truth in scientific thinking? How can we reliably measure the results of research? In this ground-breaking text, Dienes undertakes a comprehensive historical analysis of the dominant schools of thought, key theories and influential thinkers that have progressed the foundational principles and characteristics that typify scientific research methodology today. This book delivers a masterfully simple, `though not simplistic', introduction to the core arguments surrounding Popper, Kuhn and Lakatos, Fisher and Royall, Neyman and Pearson and Bayes. Subsequently, this book clarifies the prevalent misconceptions that surround such theoretical perspectives in psychology today, providing an especially accessible critique for student readers. ~ This book launches an informative inquiry into the methods by which psychologists throughout history have arrived at the conclusions of research, equipping readers with the knowledge to accurately design and evaluate their own research and gain confidence in critiquing results in psychology research. Particular attention is given to understanding methods of measuring the falsifiability of statements, probabilities and the differing views on statistical inference. An illuminating book for any undergraduate psychology student taking courses in critical thinking, research methods, BPS's core area `conceptual and historical issues' as well as those studying masters, phd's and experienced researchers.},
  language = {English},
  publisher = {{Red Globe Press}},
  author = {Zoltan Dienes},
  month = {feb},
  year = {2008},
}

@Book{efronComputerAgeStatistical2016,
  address = {{New York, NY}},
  edition = {1 edition},
  title = {Computer {{Age Statistical Inference}}: {{Algorithms}}, {{Evidence}}, and {{Data Science}}},
  isbn = {978-1-107-14989-2},
  shorttitle = {Computer {{Age Statistical Inference}}},
  abstract = {The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. 'Big data', 'data science', and 'machine learning' have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going? This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories - Bayesian, frequentist, Fisherian - individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction of statistics and data science.},
  language = {English},
  publisher = {{Cambridge University Press}},
  author = {Bradley Efron and Trevor Hastie},
  month = {jul},
  year = {2016},
}

@Book{efronComputerAgeStatistical2016,
  address = {{New York, NY}},
  edition = {1 edition},
  title = {Computer {{Age Statistical Inference}}: {{Algorithms}}, {{Evidence}}, and {{Data Science}}},
  isbn = {978-1-107-14989-2},
  shorttitle = {Computer {{Age Statistical Inference}}},
  abstract = {The twenty-first century has seen a breathtaking expansion of statistical methodology, both in scope and in influence. 'Big data', 'data science', and 'machine learning' have become familiar terms in the news, as statistical methods are brought to bear upon the enormous data sets of modern science and commerce. How did we get here? And where are we going? This book takes us on an exhilarating journey through the revolution in data analysis following the introduction of electronic computation in the 1950s. Beginning with classical inferential theories - Bayesian, frequentist, Fisherian - individual chapters take up a series of influential topics: survival analysis, logistic regression, empirical Bayes, the jackknife and bootstrap, random forests, neural networks, Markov chain Monte Carlo, inference after model selection, and dozens more. The distinctly modern approach integrates methodology and algorithms with statistical inference. The book ends with speculation on the future direction of statistics and data science.},
  language = {English},
  publisher = {{Cambridge University Press}},
  author = {Bradley Efron and Trevor Hastie},
  month = {jul},
  year = {2016},
}

@Book{dienesUnderstandingPsychologyScience2008,
  address = {{New York}},
  edition = {2008 edition},
  title = {Understanding {{Psychology}} as a {{Science}}: {{An Introduction}} to {{Scientific}} and {{Statistical Inference}}},
  isbn = {978-0-230-54231-0},
  shorttitle = {Understanding {{Psychology}} as a {{Science}}},
  abstract = {How can we objectively define categories of truth in scientific thinking? How can we reliably measure the results of research? In this ground-breaking text, Dienes undertakes a comprehensive historical analysis of the dominant schools of thought, key theories and influential thinkers that have progressed the foundational principles and characteristics that typify scientific research methodology today. This book delivers a masterfully simple, `though not simplistic', introduction to the core arguments surrounding Popper, Kuhn and Lakatos, Fisher and Royall, Neyman and Pearson and Bayes. Subsequently, this book clarifies the prevalent misconceptions that surround such theoretical perspectives in psychology today, providing an especially accessible critique for student readers. ~ This book launches an informative inquiry into the methods by which psychologists throughout history have arrived at the conclusions of research, equipping readers with the knowledge to accurately design and evaluate their own research and gain confidence in critiquing results in psychology research. Particular attention is given to understanding methods of measuring the falsifiability of statements, probabilities and the differing views on statistical inference. An illuminating book for any undergraduate psychology student taking courses in critical thinking, research methods, BPS's core area `conceptual and historical issues' as well as those studying masters, phd's and experienced researchers.},
  language = {English},
  publisher = {{Red Globe Press}},
  author = {Zoltan Dienes},
  month = {feb},
  year = {2008},
}
@Article{hesterbergWhatTeachersShould2015,
  title = {What {{Teachers Should Know About}} the {{Bootstrap}}: {{Resampling}} in the {{Undergraduate Statistics Curriculum}}},
  volume = {69},
  issn = {0003-1305, 1537-2731},
  shorttitle = {What {{Teachers Should Know About}} the {{Bootstrap}}},
  language = {en},
  number = {4},
  journal = {The American Statistician},
  doi = {10.1080/00031305.2015.1089789},
  author = {Tim C. Hesterberg},
  month = {oct},
  year = {2015},
  keywords = {Statistics - Methodology,62-01 (Primary) 62G09 (Secondary),G.3,I.6.8,K.3.0,Statistics - Other Statistics},
  pages = {371-386},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2GAXVQZS/Hesterberg - 2015 - What Teachers Should Know About the Bootstrap Res.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/WH4ERBM9/Hesterberg - 2014 - What Teachers Should Know about the Bootstrap Res.pdf},
}

@Article{rousseletPercentileBootstrapTeaser,
  title = {The Percentile Bootstrap: A Teaser with Step-by-Step Instructions in {{R}}},
  shorttitle = {The Percentile Bootstrap},
  abstract = {The percentile bootstrap is the Swiss Army Knife of statistics: it is a non-parametric method based on data-driven simulations. It can be applied to many statistical problems, as a substitute to standard parametric approaches, or in situations where parametric methods do not exist. In this tutorial, we cover R code to implement the percentile bootstrap in a few situations: one-sample estimation, group comparisons of measures of central tendency and spread, inferences about correlation coefficients and differences between correlations. For each example, we explain how to derive a bootstrap distribution, and how to get a confidence interval and a P value from that distribution. We also demonstrate how to run a simulation to assess the behaviour of the bootstrap. In some situations, the bootstrap performs poorly, such as when making inferences about the mean. But for other purposes, it is the only known method that works well over a broad range of situations, such as when comparing medians and there are tied (duplicated) values. More broadly, combining the percentile bootstrap with robust estimators, roughly meaning estimators that are not overly sensitive to outliers, the bootstrap can help users gain a deeper perspective about their data, relative to conventional methods.},
  doi = {10.31234/osf.io/kxarf},
  author = {Guillaume A Rousselet and Cyril R Pernet and Rand R. Wilcox},
}

@Article{hesterbergWhatTeachersShould2015,
  title = {What {{Teachers Should Know About}} the {{Bootstrap}}: {{Resampling}} in the {{Undergraduate Statistics Curriculum}}},
  volume = {69},
  issn = {0003-1305, 1537-2731},
  shorttitle = {What {{Teachers Should Know About}} the {{Bootstrap}}},
  language = {en},
  number = {4},
  journal = {The American Statistician},
  doi = {10.1080/00031305.2015.1089789},
  author = {Tim C. Hesterberg},
  month = {oct},
  year = {2015},
  pages = {371-386},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CE5ZGJER/Hesterberg - 2015 - What Teachers Should Know About the Bootstrap Res.pdf},
}
@Book{cantyBootBootstrapSPlus2017,
  title = {Boot: {{Bootstrap R}} ({{S}}-{{Plus}}) {{Functions}}},
  author = {Angelo Canty and B. D. Ripley},
  year = {2017},
}

@Book{cantyBootBootstrapSPlus2017,
  title = {Boot: {{Bootstrap R}} ({{S}}-{{Plus}}) {{Functions}}},
  author = {Angelo Canty and B. D. Ripley},
  year = {2017},
}
@Book{davisonBootstrapMethodsTheir1997,
  address = {{Cambridge}},
  title = {Bootstrap {{Methods}} and {{Their Applications}}},
  publisher = {{Cambridge University Press}},
  author = {A. C. Davison and D. V. Hinkley},
  year = {1997},
}

@Book{davisonBootstrapMethodsTheir1997,
  address = {{Cambridge}},
  title = {Bootstrap {{Methods}} and {{Their Applications}}},
  publisher = {{Cambridge University Press}},
  author = {A. C. Davison and D. V. Hinkley},
  year = {1997},
}
@Article{kruschkeBayesianNewStatistics2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  volume = {25},
  issn = {1069-9384, 1531-5320},
  shorttitle = {The {{Bayesian New Statistics}}},
  language = {en},
  number = {1},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/s13423-016-1221-4},
  author = {John K. Kruschke and Torrin M. Liddell},
  month = {feb},
  year = {2018},
  pages = {178-206},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/2XPF9RAC/Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf},
}

@Article{cummingNewStatisticsWhy2014,
  title = {The {{New Statistics}}: {{Why}} and {{How}}},
  volume = {25},
  issn = {0956-7976, 1467-9280},
  shorttitle = {The {{New Statistics}}},
  language = {en},
  number = {1},
  journal = {Psychological Science},
  doi = {10.1177/0956797613504966},
  author = {Geoff Cumming},
  month = {jan},
  year = {2014},
  pages = {7-29},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/YJ7CDYI2/Cumming - 2014 - The New Statistics Why and How.pdf},
}
@Article{gelmanAreConfidenceIntervals2019,
  title = {Are Confidence Intervals Better Termed ``Uncertainty Intervals''?},
  issn = {0959-8138, 1756-1833},
  language = {en},
  journal = {BMJ},
  doi = {10.1136/bmj.l5381},
  author = {Andrew Gelman and Sander Greenland},
  month = {sep},
  year = {2019},
  pages = {l5381},
}
@Article{sainaniMagnitudeBasedInference2019,
  title = {Magnitude-{{Based Inference}} Is {{Not Bayesian}} and Is {{Not}} a {{Valid Method}} of {{Inference}}},
  issn = {0905-7188, 1600-0838},
  language = {en},
  journal = {Scandinavian Journal of Medicine \& Science in Sports},
  doi = {10.1111/sms.13491},
  author = {Kristin L. Sainani and Keith R. Lohse and Paul Remy Jones and Andrew Vickers},
  month = {may},
  year = {2019},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/BD5X7TDX/Sainani et al. - 2019 - Magnitude‐Based Inference is Not Bayesian and is N.pdf},
}

@Article{barkerInferenceMagnitudesEffects2008,
  title = {Inference {{About Magnitudes}} of {{Effects}}},
  volume = {3},
  issn = {1555-0265, 1555-0273},
  abstract = {In a recent commentary on statistical inference, Batterham and Hopkins1 advocated an approach to statistical inference centered on expressions of uncertainty in parameters. After criticizing an approach to statistical inference driven by null hypothesis testing, they proposed a method of ``magnitude-based'' inference and then claimed that this approach is essentially Bayesian but with no prior assumption about the true value of the parameter. In this commentary, after we address the issues raised by Batterham and Hopkins, we show that their method is ``approximately'' Bayesian and rather than assuming no prior information their approach has a very specific, but hidden, joint prior on parameters. To correctly adopt the type of inference advocated by Batterham and Hopkins, sport scientists need to use fully Bayesian methods of analysis.},
  language = {en},
  number = {4},
  journal = {International Journal of Sports Physiology and Performance},
  doi = {10.1123/ijspp.3.4.547},
  author = {Richard J. Barker and Matthew {R. Schofield}},
  month = {dec},
  year = {2008},
  pages = {547-557},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/WAA2KMSC/Barker and R. Schofield - 2008 - Inference About Magnitudes of Effects.pdf},
}
@Article{kruschkeBayesianDataAnalysis2018,
  title = {Bayesian Data Analysis for Newcomers},
  volume = {25},
  issn = {1069-9384, 1531-5320},
  language = {en},
  number = {1},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/s13423-017-1272-1},
  author = {John K. Kruschke and Torrin M. Liddell},
  month = {feb},
  year = {2018},
  pages = {155-177},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/IUEGZLNS/Kruschke and Liddell - 2018 - Bayesian data analysis for newcomers.pdf},
}
@Article{lakensEquivalenceTestsPractical2017,
  title = {Equivalence {{Tests}}: {{A Practical Primer}} for {\emph{t}} {{Tests}}, {{Correlations}}, and {{Meta}}-{{Analyses}}},
  volume = {8},
  issn = {1948-5506, 1948-5514},
  shorttitle = {Equivalence {{Tests}}},
  abstract = {Scientists should be able to provide support for the absence of a meaningful effect. Currently, researchers often incorrectly conclude an effect is absent based a nonsignificant result. A widely recommended approach within a frequentist framework is to test for equivalence. In equivalence tests, such as the two one-sided tests (TOST) procedure discussed in this article, an upper and lower equivalence bound is specified based on the smallest effect size of interest. The TOST procedure can be used to statistically reject the presence of effects large enough to be considered worthwhile. This practical primer with accompanying spreadsheet and R package enables psychologists to easily perform equivalence tests (and power analyses) by setting equivalence bounds based on standardized effect sizes and provides recommendations to prespecify equivalence bounds. Extending your statistical tool kit with equivalence tests is an easy way to improve your statistical and theoretical inferences.},
  language = {en},
  number = {4},
  journal = {Social Psychological and Personality Science},
  doi = {10.1177/1948550617697177},
  author = {Dani{\"e}l Lakens},
  month = {may},
  year = {2017},
  pages = {355-362},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/J7R9NPIV/Lakens - 2017 - Equivalence Tests A Practical Primer for iti.pdf},
}
@Article{batterhamMakingMeaningfulInferences2006,
  title = {Making {{Meaningful Inferences About Magnitudes}}},
  volume = {1},
  issn = {1555-0265, 1555-0273},
  number = {1},
  journal = {International Journal of Sports Physiology and Performance},
  doi = {10.1123/ijspp.1.1.50},
  author = {Alan M. Batterham and William G. Hopkins},
  month = {mar},
  year = {2006},
  pages = {50-57},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/M3YSW855/Batterham and Hopkins - 2006 - Making Meaningful Inferences About Magnitudes.pdf},
}
@Article{hopkinsVindicationMagnitudeBasedInference2018,
  title = {The {{Vindication}} of {{Magnitude}}-{{Based Inference}}},
  language = {en},
  author = {Will Hopkins and Alan Batterham},
  year = {2018},
  pages = {12},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/XZ8PG43Q/Hopkins and Batterham - 2018 - The Vindication of Magnitude-Based Inference.pdf},
}

@Article{sainaniProblemMagnitudebasedInference2018,
  title = {The {{Problem}} with {"}{{Magnitude}}-Based {{Inference}}{"}},
  volume = {50},
  issn = {1530-0315},
  abstract = {PURPOSE: A statistical method called {"}magnitude-based inference{"} (MBI) has gained a following in the sports science literature, despite concerns voiced by statisticians. Its proponents have claimed that MBI exhibits superior type I and type II error rates compared with standard null hypothesis testing for most cases. I have performed a reanalysis to evaluate this claim.
METHODS: Using simulation code provided by MBI's proponents, I estimated type I and type II error rates for clinical and nonclinical MBI for a range of effect sizes, sample sizes, and smallest important effects. I plotted these results in a way that makes transparent the empirical behavior of MBI. I also reran the simulations after correcting mistakes in the definitions of type I and type II error provided by MBI's proponents. Finally, I confirmed the findings mathematically; and I provide general equations for calculating MBI's error rates without the need for simulation.
RESULTS: Contrary to what MBI's proponents have claimed, MBI does not exhibit {"}superior{"} type I and type II error rates to standard null hypothesis testing. As expected, there is a tradeoff between type I and type II error. At precisely the small-to-moderate sample sizes that MBI's proponents deem {"}optimal,{"} MBI reduces the type II error rate at the cost of greatly inflating the type I error rate-to two to six times that of standard hypothesis testing.
CONCLUSIONS: Magnitude-based inference exhibits worrisome empirical behavior. In contrast to standard null hypothesis testing, which has predictable type I error rates, the type I error rates for MBI vary widely depending on the sample size and choice of smallest important effect, and are often unacceptably high. Magnitude-based inference should not be used.},
  language = {eng},
  number = {10},
  journal = {Medicine and Science in Sports and Exercise},
  doi = {10.1249/MSS.0000000000001645},
  author = {Kristin L. Sainani},
  month = {oct},
  year = {2018},
  pages = {2166-2176},
  pmid = {29683920},
}

@Article{nevillCanWeTrust2018,
  title = {Can We Trust ``{{Magnitude}}-Based Inference''?},
  volume = {36},
  issn = {0264-0414},
  number = {24},
  journal = {Journal of Sports Sciences},
  doi = {10.1080/02640414.2018.1516004},
  author = {Alan M. Nevill and A. Mark Williams and Colin Boreham and Eric S. Wallace and Gareth W. Davison and Grant Abt and Andrew M. Lane and Edward M. Winter EDITORIAL BOARD},
  month = {dec},
  year = {2018},
  pages = {2769-2770},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/EUVYBGHT/Nevill et al. - 2018 - Can we trust “Magnitude-based inference”.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/CTCNLF52/02640414.2018.html},
  pmid = {30392465},
}

@Article{borgBayesianMethodsMight2018,
  title = {Bayesian {{Methods Might Solve}} the {{Problems}} with {{Magnitude}}-Based {{Inference}}:},
  volume = {50},
  issn = {0195-9131},
  shorttitle = {Bayesian {{Methods Might Solve}} the {{Problems}} with {{Magnitude}}-Based {{Inference}}},
  language = {en},
  number = {12},
  journal = {Medicine \& Science in Sports \& Exercise},
  doi = {10.1249/MSS.0000000000001736},
  author = {David N. Borg and Geoffrey M. Minett and Ian B. Stewart and Christopher C. Drovandi},
  month = {dec},
  year = {2018},
  pages = {2609-2610},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/I7LBWNUZ/Borg et al. - 2018 - Bayesian Methods Might Solve the Problems with Mag.pdf},
}

@Article{curran-everettMagnitudebasedInferenceGood2018,
  title = {Magnitude-Based {{Inference}}: {{Good Idea}} but {{Flawed Approach}}},
  volume = {50},
  issn = {0195-9131},
  shorttitle = {Magnitude-Based {{Inference}}},
  language = {en},
  number = {10},
  journal = {Medicine \& Science in Sports \& Exercise},
  doi = {10.1249/MSS.0000000000001646},
  author = {Douglas Curran-Everett},
  month = {oct},
  year = {2018},
  pages = {2164-2165},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/5BKMVCVB/Curran-Everett - 2018 - Magnitude-based Inference Good Idea but Flawed Ap.pdf},
  ids = {curran-everettMagnitudebasedInferenceGood2018a},
}

@Article{welshMagnitudebasedInferenceStatistical2015,
  title = {``{{Magnitude}}-Based {{Inference}}'': {{A Statistical Review}}},
  volume = {47},
  issn = {0195-9131},
  shorttitle = {``{{Magnitude}}-Based {{Inference}}''},
  language = {en},
  number = {4},
  journal = {Medicine \& Science in Sports \& Exercise},
  doi = {10.1249/MSS.0000000000000451},
  author = {Alan H. Welsh and Emma J. Knight},
  month = {apr},
  year = {2015},
  pages = {874-884},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/GKGLZZAK/Welsh and Knight - 2015 - “Magnitude-based Inference” A Statistical Review.pdf},
}

@Article{sainaniProblemMagnitudebasedInference2018,
  title = {The {{Problem}} with {"}{{Magnitude}}-Based {{Inference}}{"}},
  volume = {50},
  issn = {1530-0315},
  abstract = {PURPOSE: A statistical method called {"}magnitude-based inference{"} (MBI) has gained a following in the sports science literature, despite concerns voiced by statisticians. Its proponents have claimed that MBI exhibits superior type I and type II error rates compared with standard null hypothesis testing for most cases. I have performed a reanalysis to evaluate this claim.
METHODS: Using simulation code provided by MBI's proponents, I estimated type I and type II error rates for clinical and nonclinical MBI for a range of effect sizes, sample sizes, and smallest important effects. I plotted these results in a way that makes transparent the empirical behavior of MBI. I also reran the simulations after correcting mistakes in the definitions of type I and type II error provided by MBI's proponents. Finally, I confirmed the findings mathematically; and I provide general equations for calculating MBI's error rates without the need for simulation.
RESULTS: Contrary to what MBI's proponents have claimed, MBI does not exhibit {"}superior{"} type I and type II error rates to standard null hypothesis testing. As expected, there is a tradeoff between type I and type II error. At precisely the small-to-moderate sample sizes that MBI's proponents deem {"}optimal,{"} MBI reduces the type II error rate at the cost of greatly inflating the type I error rate-to two to six times that of standard hypothesis testing.
CONCLUSIONS: Magnitude-based inference exhibits worrisome empirical behavior. In contrast to standard null hypothesis testing, which has predictable type I error rates, the type I error rates for MBI vary widely depending on the sample size and choice of smallest important effect, and are often unacceptably high. Magnitude-based inference should not be used.},
  language = {eng},
  number = {10},
  journal = {Medicine and Science in Sports and Exercise},
  doi = {10.1249/MSS.0000000000001645},
  author = {Kristin L. Sainani},
  month = {oct},
  year = {2018},
  pages = {2166-2176},
  pmid = {29683920},
}

@Article{hopkinsVindicationMagnitudeBasedInference2018,
  title = {The {{Vindication}} of {{Magnitude}}-{{Based Inference}}},
  language = {en},
  author = {Will Hopkins and Alan Batterham},
  year = {2018},
  pages = {12},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/455FRSYM/Hopkins and Batterham - 2018 - The Vindication of Magnitude-Based Inference.pdf},
}

@Article{nevillCanWeTrust2018,
  title = {Can We Trust ``{{Magnitude}}-Based Inference''?},
  volume = {36},
  issn = {0264-0414},
  number = {24},
  journal = {Journal of Sports Sciences},
  doi = {10.1080/02640414.2018.1516004},
  author = {Alan M. Nevill and A. Mark Williams and Colin Boreham and Eric S. Wallace and Gareth W. Davison and Grant Abt and Andrew M. Lane and Edward M. Winter EDITORIAL BOARD},
  month = {dec},
  year = {2018},
  pages = {2769-2770},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/EMUGULUG/Nevill et al. - 2018 - Can we trust “Magnitude-based inference”.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/HW6BN3HC/02640414.2018.html},
  pmid = {30392465},
}
@Article{makowskiUnderstandDescribeBayesian2019,
  title = {Understand and Describe Bayesian Models and Posterior Distributions Using {{bayestestR}}},
  journal = {CRAN},
  doi = {10.5281/zenodo.2556486},
  author = {Dominique Makowski and Mattan S. Ben-Shachar and Daniel L{\"u}decke},
  year = {2019},
  note = {R package},
}
@Article{makowskiIndicesEffectExistence,
  title = {Indices of {{Effect Existence}} and {{Significance}} in the {{Bayesian Framework}}},
  abstract = {Turmoil has engulfed psychological science. Causes and consequences of the reproducibility crisis are in dispute. With the hope of addressing some of its aspects, Bayesian methods are gaining increasing attention in psychological science. Some of their advantages, as opposed to the frequentist framework, are the ability to describe parameters in probabilistic terms and explicitly incorporate prior knowledge about them into the model. These issues are crucial in particular regarding the current debate about statistical significance. Bayesian methods are not necessarily the only remedy against incorrect interpretations or wrong conclusions, but there is an increasing agreement that they are one of the keys to avoid such fallacies. Nevertheless, its flexible nature is its power and weakness, for there is no agreement about what indices of ``significance'' should be computed or reported. This lack of a consensual index or guidelines, such as the frequentist p-value, further contributes to the unnecessary opacity that many non-familiar readers perceive in Bayesian statistics. Thus, this study describes and compares several Bayesian indices, provide intuitive visual representation of their ``behavior'' in relationship with common sources of variance such as sample size, magnitude of effects and also frequentist significance. The results contribute to the development of an intuitive understanding of the values that researchers report, allowing to draw sensible recommendations for Bayesian statistics description, critical for the standardization of scientific reporting.},
  doi = {10.31234/osf.io/2zexr},
  author = {Dominique Makowski and Mattan S. Ben-Shachar and SH Annabel Chen and Daniel L{\"u}decke},
}

@Article{makowskiBayestestRDescribingEffects2019,
  title = {{{bayestestR}}: {{Describing Effects}} and Their {{Uncertainty}}, {{Existence}} and {{Significance}} within the {{Bayesian Framework}}},
  volume = {4},
  issn = {2475-9066},
  shorttitle = {{{bayestestR}}},
  number = {40},
  journal = {Journal of Open Source Software},
  doi = {10.21105/joss.01541},
  author = {Dominique Makowski and Mattan Ben-Shachar and Daniel L{\"u}decke},
  month = {aug},
  year = {2019},
  pages = {1541},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/K2TB8UL3/Makowski et al. - 2019 - bayestestR Describing Effects and their Uncertain.pdf},
}
@Article{efronBayesiansFrequentistsScientists2005,
  title = {Bayesians, {{Frequentists}}, and {{Scientists}}},
  volume = {100},
  issn = {0162-1459, 1537-274X},
  language = {en},
  number = {469},
  journal = {Journal of the American Statistical Association},
  doi = {10.1198/016214505000000033},
  author = {Bradley Efron},
  month = {mar},
  year = {2005},
  pages = {1-5},
}
@Article{rousseletPracticalIntroductionBootstrap2019,
  title = {A Practical Introduction to the Bootstrap: A Versatile Method to Make Inferences by Using Data-Driven Simulations},
  shorttitle = {A Practical Introduction to the Bootstrap},
  abstract = {The bootstrap is a versatile technique that relies on data-driven simulations to make statistical inferences. When combined with robust estimators, the bootstrap can afford much more powerful and flexible inferences than is possible with standard approaches such as t-tests on means. In this R tutorial, we use detailed illustrations of bootstrap simulations to give readers an intuition of what the bootstrap does and how it can be applied to solve many practical problems, such as building confidence intervals for many aspects of the data. In particular, we illustrate how to build confidence intervals for measures of location, including measures of central tendency, in the one-sample case, for two independent and two dependent groups. We also demonstrate how to compare correlation coefficients using the bootstrap and to perform simulations to determine if the bootstrap is fit for purpose for a particular application. The tutorial also addresses two widespread misconceptions about the bootstrap: that it makes no assumptions about the data, and that it leads to robust inferences on its own. The tutorial focuses on detailed graphical descriptions, with data and code available online to reproduce the figures and analyses in the article (https://osf.io/8b4t5/).},
  doi = {10.31234/osf.io/h8ft7},
  author = {Guillaume A Rousselet and Cyril R Pernet and Rand R. Wilcox},
  year = {2019},
}

@Article{rousseletPercentileBootstrapTeaser2019,
  title = {The Percentile Bootstrap: A Teaser with Step-by-Step Instructions in {{R}}},
  shorttitle = {The Percentile Bootstrap},
  abstract = {The percentile bootstrap is the Swiss Army Knife of statistics: it is a non-parametric method based on data-driven simulations. It can be applied to many statistical problems, as a substitute to standard parametric approaches, or in situations where parametric methods do not exist. In this tutorial, we cover R code to implement the percentile bootstrap in a few situations: one-sample estimation, group comparisons of measures of central tendency and spread, inferences about correlation coefficients and differences between correlations. For each example, we explain how to derive a bootstrap distribution, and how to get a confidence interval and a P value from that distribution. We also demonstrate how to run a simulation to assess the behaviour of the bootstrap. In some situations, the bootstrap performs poorly, such as when making inferences about the mean. But for other purposes, it is the only known method that works well over a broad range of situations, such as when comparing medians and there are tied (duplicated) values. More broadly, combining the percentile bootstrap with robust estimators, roughly meaning estimators that are not overly sensitive to outliers, the bootstrap can help users gain a deeper perspective about their data, relative to conventional methods.},
  doi = {10.31234/osf.io/kxarf},
  author = {Guillaume A Rousselet and Cyril R Pernet and Rand R. Wilcox},
  year = {2019},
}
@Book{hastieElementsStatisticalLearning2009,
  address = {{New York, NY}},
  edition = {2nd ed},
  series = {Springer Series in Statistics},
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  lccn = {Q325.5 .H39 2009},
  shorttitle = {The Elements of Statistical Learning},
  publisher = {{Springer}},
  author = {Trevor Hastie and Robert Tibshirani and J. H. Friedman},
  year = {2009},
  keywords = {Bioinformatics,Computational intelligence,Data mining,Forecasting,Inference,Machine learning,Methodology,Statistics},
}
@Article{moreyFallacyPlacingConfidence2016,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  volume = {23},
  issn = {1069-9384, 1531-5320},
  language = {en},
  number = {1},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/s13423-015-0947-8},
  author = {Richard D. Morey and Rink Hoekstra and Jeffrey N. Rouder and Michael D. Lee and Eric-Jan Wagenmakers},
  month = {feb},
  year = {2016},
  pages = {103-123},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/79WVEW8L/Morey et al. - 2016 - The fallacy of placing confidence in confidence in.pdf},
}
@Book{spiegelhalterArtStatisticsHow2019,
  address = {{New York}},
  title = {The Art of Statistics: How to Learn from Data},
  isbn = {978-1-5416-1851-0},
  shorttitle = {The Art of Statistics},
  abstract = {{"}In The Art of Statistics, statistician David Spiegelhalter shows readers how to derive knowledge from raw data by focusing on the concepts and connections behind the math. Drawing on real world examples to introduce complex issues, he shows us how mathematicians can use statistical science to solve problems, and it teaches us how we too can think like statisticians{"}--},
  publisher = {{Basic Books, an imprint of Perseus Books, a subsidiary of Hachette Book Group}},
  author = {David Spiegelhalter},
  year = {2019},
}
@Article{wagenmakersPracticalSolutionPervasive2007,
  title = {A Practical Solution to the Pervasive Problems Ofp Values},
  volume = {14},
  issn = {1069-9384, 1531-5320},
  language = {en},
  number = {5},
  journal = {Psychonomic Bulletin \& Review},
  doi = {10.3758/BF03194105},
  author = {Eric-Jan Wagenmakers},
  month = {oct},
  year = {2007},
  pages = {779-804},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/ZTECSY9M/Wagenmakers - 2007 - A practical solution to the pervasive problems ofp.pdf},
}
@Article{kruschkeBayesianEstimationSupersedes2013,
  title = {Bayesian Estimation Supersedes the t Test.},
  volume = {142},
  issn = {1939-2222, 0096-3445},
  language = {en},
  number = {2},
  journal = {Journal of Experimental Psychology: General},
  doi = {10.1037/a0029146},
  author = {John K. Kruschke},
  year = {2013},
  pages = {573-603},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/IXP9SNNK/Kruschke - Bayesian estimation supersedes the t test.pdf},
}
@Article{sainaniClinicalStatisticalSignificance2012,
  title = {Clinical {{Versus Statistical Significance}}},
  volume = {4},
  issn = {19341482},
  language = {en},
  number = {6},
  journal = {PM\&R},
  doi = {10.1016/j.pmrj.2012.04.014},
  author = {Kristin L. Sainani},
  month = {jun},
  year = {2012},
  pages = {442-445},
}
@Article{jovanovicStatisticalModellingSports2019,
  title = {Statistical {{Modelling}} for {{Sports Scientists}}: {{Practical Introduction Using R}} ({{Part}} 1)},
  shorttitle = {Statistical {{Modelling}} for {{Sports Scientists}}},
  abstract = {The aim of this paper is to provide an overview of the three classes of tasks in the statistical modelling: description, prediction and causal inference (Hern{\'a}n, Hsu \&amp; Healy, 2019). Statistical inference is often required for all three tasks. Short introduction to frequentist null-hypothesis testing, Bayesian estimation, and bootstrap is provided. Special attention is given to the practical significance by the introduction of magnitude-based estimators and statistical inference using the concept of smallest effect size of interest (SESOI). Measurement error is discussed with the particular aim of interpreting individual change scores. In the second part of this paper, common sport science problems are introduced and analyzed using for that purpose written package in R language (RStudio Team, 2016; R Core Team, 2018).},
  journal = {SportRxiv},
  doi = {10.31236/osf.io/dnq3m},
  author = {Mladen Jovanovic},
  month = {sep},
  year = {2019},
}
@Article{textorRobustCausalInference2017,
  title = {Robust Causal Inference Using Directed Acyclic Graphs: The {{R}} Package `Dagitty'},
  issn = {0300-5771, 1464-3685},
  shorttitle = {Robust Causal Inference Using Directed Acyclic Graphs},
  abstract = {Directed acyclic graphs (DAGs), which offer systematic representations of causal relationships, have become an established framework for the analysis of causal inference in epidemiology, often being used to determine covariate adjustment sets for minimizing confounding bias. DAGitty is a popular web application for drawing and analysing DAGs. Here we introduce the R package `dagitty', which provides access to all of the capabilities of the DAGitty web application within the R platform for statistical computing, and also offers several new functions. We describe how the R package `dagitty' can be used to: evaluate whether a DAG is consistent with the dataset it is intended to represent; enumerate `statistically equivalent' but causally different DAGs; and identify exposureoutcome adjustment sets that are valid for causally different but statistically equivalent DAGs. This functionality enables epidemiologists to detect causal misspecifications in DAGs and make robust inferences that remain valid for a range of different DAGs. The R package `dagitty' is available through the comprehensive R archive network (CRAN) at [https://cran.r-project.org/web/packages/dagitty/]. The source code is available on github at [https://github.com/jtextor/dagitty]. The web application `DAGitty' is free software, licensed under the GNU general public licence (GPL) version 2 and is available at [http:// dagitty.net/].},
  language = {en},
  journal = {International Journal of Epidemiology},
  doi = {10.1093/ije/dyw341},
  author = {Johannes Textor and Benito {van der Zander} and Mark S. Gilthorpe and Maciej Li{\a's}kiewicz and George T.H. Ellison},
  month = {jan},
  year = {2017},
  pages = {dyw341},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/4SRZPJS3/Textor et al. - 2017 - Robust causal inference using directed acyclic gra.pdf},
}

@Article{textorRobustCausalInference2017,
  title = {Robust Causal Inference Using Directed Acyclic Graphs: The {{R}} Package `Dagitty'},
  issn = {0300-5771, 1464-3685},
  shorttitle = {Robust Causal Inference Using Directed Acyclic Graphs},
  abstract = {Directed acyclic graphs (DAGs), which offer systematic representations of causal relationships, have become an established framework for the analysis of causal inference in epidemiology, often being used to determine covariate adjustment sets for minimizing confounding bias. DAGitty is a popular web application for drawing and analysing DAGs. Here we introduce the R package `dagitty', which provides access to all of the capabilities of the DAGitty web application within the R platform for statistical computing, and also offers several new functions. We describe how the R package `dagitty' can be used to: evaluate whether a DAG is consistent with the dataset it is intended to represent; enumerate `statistically equivalent' but causally different DAGs; and identify exposureoutcome adjustment sets that are valid for causally different but statistically equivalent DAGs. This functionality enables epidemiologists to detect causal misspecifications in DAGs and make robust inferences that remain valid for a range of different DAGs. The R package `dagitty' is available through the comprehensive R archive network (CRAN) at [https://cran.r-project.org/web/packages/dagitty/]. The source code is available on github at [https://github.com/jtextor/dagitty]. The web application `DAGitty' is free software, licensed under the GNU general public licence (GPL) version 2 and is available at [http:// dagitty.net/].},
  language = {en},
  journal = {International Journal of Epidemiology},
  doi = {10.1093/ije/dyw341},
  author = {Johannes Textor and Benito {van der Zander} and Mark S. Gilthorpe and Maciej Li{\a's}kiewicz and George T.H. Ellison},
  month = {jan},
  year = {2017},
  pages = {dyw341},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/XEVX6Y5Y/Textor et al. - 2017 - Robust causal inference using directed acyclic gra.pdf},
}
@Article{makowskiIndicesEffectExistence2019,
  title = {Indices of {{Effect Existence}} and {{Significance}} in the {{Bayesian Framework}}},
  abstract = {Turmoil has engulfed psychological science. Causes and consequences of the reproducibility crisis are in dispute. With the hope of addressing some of its aspects, Bayesian methods are gaining increasing attention in psychological science. Some of their advantages, as opposed to the frequentist framework, are the ability to describe parameters in probabilistic terms and explicitly incorporate prior knowledge about them into the model. These issues are crucial in particular regarding the current debate about statistical significance. Bayesian methods are not necessarily the only remedy against incorrect interpretations or wrong conclusions, but there is an increasing agreement that they are one of the keys to avoid such fallacies. Nevertheless, its flexible nature is its power and weakness, for there is no agreement about what indices of ``significance'' should be computed or reported. This lack of a consensual index or guidelines, such as the frequentist p-value, further contributes to the unnecessary opacity that many non-familiar readers perceive in Bayesian statistics. Thus, this study describes and compares several Bayesian indices, provide intuitive visual representation of their ``behavior'' in relationship with common sources of variance such as sample size, magnitude of effects and also frequentist significance. The results contribute to the development of an intuitive understanding of the values that researchers report, allowing to draw sensible recommendations for Bayesian statistics description, critical for the standardization of scientific reporting.},
  doi = {10.31234/osf.io/2zexr},
  author = {Dominique Makowski and Mattan S. Ben-Shachar and SH Annabel Chen and Daniel L{\"u}decke},
  month = {sep},
  year = {2019},
}

@Article{chaiRootMeanSquare2014,
  title = {Root Mean Square Error ({{RMSE}}) or Mean Absolute Error ({{MAE}})? \textendash{} {{Arguments}} against Avoiding {{RMSE}} in the Literature},
  volume = {7},
  issn = {1991-9603},
  shorttitle = {Root Mean Square Error ({{RMSE}}) or Mean Absolute Error ({{MAE}})?},
  language = {en},
  number = {3},
  journal = {Geoscientific Model Development},
  doi = {10.5194/gmd-7-1247-2014},
  author = {T. Chai and R. R. Draxler},
  month = {jun},
  year = {2014},
  pages = {1247-1250},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/6CMP3V56/Chai and Draxler - 2014 - Root mean square error (RMSE) or mean absolute err.pdf},
}

@Article{RJ-2017-016,
  title = {Pdp: {{An R Package}} for {{Constructing Partial Dependence Plots}}},
  volume = {9},
  number = {1},
  journal = {The R Journal},
  doi = {10.32614/RJ-2017-016},
  author = {Brandon M. Greenwell},
  year = {2017},
  pages = {421-436},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/C8RI8P3M/Greenwell - 2017 - pdp An R Package for Constructing Partial Depende.pdf},
}
@Book{altmannLimitationsInterpretableMachine2019,
  title = {Limitations of {{Interpretable Machine Learning Methods}}},
  abstract = {This book explains limitations of current methods in interpretable machine learning. The methods include partial dependence plots (PDP), Accumulated Local Effects (ALE), permutation feature importance, leave-one-covariate out (LOCO) and local interpretable model-agnostic explanations (LIME). All of those methods can be used to explain the behavior and predictions of trained machine learning models. But the interpretation methods might not work well in the following cases:

if a model models interactions (e.g. when a random forest is used)
if features strongly correlate with each other
if the model does not correctly model causal relationships
if parameters of the interpretation method are not set correctly
This book is the outcome of the seminar ``Limitations of Interpretable Machine Learning'' which took place in summer 2019 at the Department of Statistics, LMU Munich.},
  author = {Thomas Altmann and Jakob Bodensteiner and Cord Dankers and Thommy Dassen and Nikolas Fritz and Sebastian Gruber and Philipp Kopper and Veronika Kronseder and Moritz Wagner and Emanuel Renkl},
  year = {2019},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/UHQW3XBN/iml_methods_limitations.html},
}
@Book{biecekPredictiveModelsExplore2019,
  title = {Predictive {{Models}}: {{Explore}}, {{Explain}}, and {{Debug}}},
  shorttitle = {Predictive {{Models}}},
  abstract = {This book introduces key concepts for exploration, explanation and visualization of complex predictive models.},
  author = {Przemyslaw Biecek and Tomasz Burzykowski},
  month = {dec},
  year = {2019},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/VRU6W6PK/PM_VEE.html},
}
@Article{wiki:xxx,
  title = {Causal Model},
  author = {{Wikipedia contributors}},
  year = {2019},
}
@Book{lantzMachineLearningExpert2019,
  title = {Machine Learning with {{R}}: Expert Techniques for Predictive Modeling},
  isbn = {978-1-78829-586-4},
  shorttitle = {Machine Learning with {{R}}},
  language = {English},
  author = {Brett Lantz},
  year = {2019},
  note = {OCLC: 1101923552},
}
@Article{chaiRootMeanSquare2014,
  title = {Root Mean Square Error ({{RMSE}}) or Mean Absolute Error ({{MAE}})? \textendash{} {{Arguments}} against Avoiding {{RMSE}} in the Literature},
  volume = {7},
  issn = {1991-9603},
  shorttitle = {Root Mean Square Error ({{RMSE}}) or Mean Absolute Error ({{MAE}})?},
  language = {en},
  number = {3},
  journal = {Geoscientific Model Development},
  doi = {10.5194/gmd-7-1247-2014},
  author = {T. Chai and R. R. Draxler},
  month = {jun},
  year = {2014},
  pages = {1247-1250},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/6CMP3V56/Chai and Draxler - 2014 - Root mean square error (RMSE) or mean absolute err.pdf},
}

@Article{botchkarevNewTypologyDesign2019,
  title = {A {{New Typology Design}} of {{Performance Metrics}} to {{Measure Errors}} in {{Machine Learning Regression Algorithms}}},
  volume = {14},
  issn = {1555-1229, 1555-1237},
  language = {en},
  journal = {Interdisciplinary Journal of Information, Knowledge, and Management},
  doi = {10.28945/4184},
  author = {Alexei Botchkarev},
  year = {2019},
  pages = {045-076},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/GS74D7V6/2019 - A New Typology Design of Performance Metrics to Me.pdf},
}

@Article{willmottAdvantagesMeanAbsolute2005,
  title = {Advantages of the Mean Absolute Error ({{MAE}}) over the Root Mean Square Error ({{RMSE}}) in Assessing Average Model Performance},
  volume = {30},
  issn = {0936-577X, 1616-1572},
  abstract = {The relative abilities of 2, dimensioned statistics \textemdash{} the root-mean-square error (RMSE) and the mean absolute error (MAE) \textemdash{} to describe average model-performance error are examined. The RMSE is of special interest because it is widely reported in the climatic and environmental literature; nevertheless, it is an inappropriate and misinterpreted measure of average error. RMSE is inappropriate because it is a function of 3 characteristics of a set of errors, rather than of one (the average error). RMSE varies with the variability within the distribution of error magnitudes and with the square root of the number of errors (n1/2), as well as with the average-error magnitude (MAE). Our findings indicate that MAE is a more natural measure of average error, and (unlike RMSE) is unambiguous. Dimensioned evaluations and inter-comparisons of average model-performance error, therefore, should be based on MAE.},
  language = {en},
  journal = {Climate Research},
  doi = {10.3354/cr030079},
  author = {Cj Willmott and K Matsuura},
  year = {2005},
  pages = {79-82},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/4F78ZXD9/Willmott and Matsuura - 2005 - Advantages of the mean absolute error (MAE) over t.pdf},
}

@Article{barronGeneralAdaptiveRobust2019,
  archiveprefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.03077},
  primaryclass = {cs, stat},
  title = {A {{General}} and {{Adaptive Robust Loss Function}}},
  abstract = {We present a generalization of the Cauchy/Lorentzian, Geman-McClure, Welsch/Leclerc, generalized Charbonnier, Charbonnier/pseudo-Huber/L1-L2, and L2 loss functions. By introducing robustness as a continuous parameter, our loss function allows algorithms built around robust loss minimization to be generalized, which improves performance on basic vision tasks such as registration and clustering. Interpreting our loss as the negative log of a univariate density yields a general probability distribution that includes normal and Cauchy distributions as special cases. This probabilistic interpretation enables the training of neural networks in which the robustness of the loss automatically adapts itself during training, which improves performance on learning-based tasks such as generative image synthesis and unsupervised monocular depth estimation, without requiring any manual parameter tuning.},
  journal = {arXiv:1701.03077 [cs, stat]},
  author = {Jonathan T. Barron},
  month = {apr},
  year = {2019},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/7YEFM5C4/Barron - 2019 - A General and Adaptive Robust Loss Function.pdf;/Users/Mladen/OneDrive/Documents/3-Archive/Reference Managers/ZoteroLibrary/storage/MC52M3I4/1701.html},
}

@article{jDifferentWaysEstimate2018,
	title = {Different ways to estimate treatment effects in randomised controlled trials},
	volume = {10},
	issn = {24518654},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2451865417301849},
	doi = {10.1016/j.conctc.2018.03.008},
	language = {en},
	urldate = {2020-01-16},
	journal = {Contemporary Clinical Trials Communications},
	author = {J, Twisk and L, Bosman and T, Hoekstra and J, Rijnhart and M, Welten and M, Heymans},
	month = jun,
	year = {2018},
	pages = {80--85},
	file = {Full Text:/Users/mladenjovanovic/Zotero/storage/XSNVIGVV/J et al. - 2018 - Different ways to estimate treatment effects in ra.pdf:application/pdf}
}

@book{borsboomMeasuringMindConceptual2009,
	address = {Cambridge},
	title = {Measuring the mind: conceptual issues in modern psychometrics},
	isbn = {978-0-521-10284-1},
	shorttitle = {Measuring the mind},
	language = {eng},
	publisher = {Cambridge University Press},
	author = {Borsboom, Denny},
	year = {2009},
	note = {OCLC: 276648004}
}


@article{ludbrookLinearRegressionAnalysis2010,
  title = {Linear Regression Analysis for Comparing Two Measurers or Methods of Measurement: {{But}} Which Regression?: {{Linear}} Regression for Comparing Methods},
  shorttitle = {Linear Regression Analysis for Comparing Two Measurers or Methods of Measurement},
  author = {Ludbrook, John},
  year = {2010},
  month = mar,
  volume = {37},
  pages = {692--699},
  issn = {03051870, 14401681},
  doi = {10.1111/j.1440-1681.2010.05376.x},
  file = {/Users/mladenjovanovic/Zotero/storage/NRMXX3II/Ludbrook - 2010 - Linear regression analysis for comparing two measu.pdf},
  journal = {Clinical and Experimental Pharmacology and Physiology},
  language = {en},
  number = {7}
}

@article{ludbrookPrimerBiomedicalScientists2012,
  title = {A Primer for Biomedical Scientists on How to Execute {{Model II}} Linear Regression Analysis: {{Model II}} Linear Regression Analysis},
  shorttitle = {A Primer for Biomedical Scientists on How to Execute {{Model II}} Linear Regression Analysis},
  author = {Ludbrook, John},
  year = {2012},
  month = apr,
  volume = {39},
  pages = {329--335},
  issn = {03051870},
  doi = {10.1111/j.1440-1681.2011.05643.x},
  file = {/Users/mladenjovanovic/Zotero/storage/VG6X25S9/Ludbrook - 2012 - A primer for biomedical scientists on how to execu.pdf},
  journal = {Clinical and Experimental Pharmacology and Physiology},
  language = {en},
  number = {4}
}

@article{ludbrookSPECIALARTICLECOMPARING1997,
  title = {{{SPECIAL ARTICLE COMPARING METHODS OF MEASUREMENT}}},
  author = {Ludbrook, John},
  year = {1997},
  month = feb,
  volume = {24},
  pages = {193--203},
  issn = {0305-1870, 1440-1681},
  doi = {10.1111/j.1440-1681.1997.tb01807.x},
  file = {/Users/mladenjovanovic/Zotero/storage/QGRNLSWC/Ludbrook - 1997 - SPECIAL ARTICLE COMPARING METHODS OF MEASUREMENT.pdf},
  journal = {Clinical and Experimental Pharmacology and Physiology},
  language = {en},
  number = {2}
}

@article{ludbrookStatisticalTechniquesComparing2002,
  title = {Statistical {{Techniques For Comparing Measurers And Methods Of Measurement}}: {{A Critical Review}}},
  shorttitle = {Statistical {{Techniques For Comparing Measurers And Methods Of Measurement}}},
  author = {Ludbrook, John},
  year = {2002},
  month = jul,
  volume = {29},
  pages = {527--536},
  issn = {0305-1870, 1440-1681},
  doi = {10.1046/j.1440-1681.2002.03686.x},
  file = {/Users/mladenjovanovic/Zotero/storage/HMGFAWHM/Ludbrook - 2002 - Statistical Techniques For Comparing Measurers And.pdf},
  journal = {Clinical and Experimental Pharmacology and Physiology},
  language = {en},
  number = {7}
}

@article{mullineauxAssessmentBiasComparing1999,
  title = {Assessment of {{Bias}} in {{Comparing Measurements}}: {{A Reliability Example}}},
  shorttitle = {Assessment of {{Bias}} in {{Comparing Measurements}}},
  author = {Mullineaux, David R. and Barnes, Christopher A. and Batterham, Alan M.},
  year = {1999},
  month = oct,
  volume = {3},
  pages = {195--205},
  issn = {1091-367X, 1532-7841},
  doi = {10.1207/s15327841mpee0304_1},
  abstract = {Comparative analyses of a variable measured twice or against a "gold standard" technique should explore the existence of any fixed and proportional biases between the 2 measurements. Levels of agreement (LOA) consider these biases together and least products regression (LPR) considertheir effect independently.To compare the use of LOA and LPR, the peak torque extension (PTE) of the knee at 2.1 radlsec during isokineticdynamometrywas obtainedon 2 separatedays (N= 17).The mean PTE (with standarddeviationsin parentheses)was found to be 93.6(13.9)N . m on Day 1and 92.5 (1 1.5)N . m on Day 2. The LOA were 1.06 i 10.80N .m (95\% confidence), and the LPR's (with 95\%confidenceintervals in parentheses)interceptwas -17.7 N . m (-37.4 to 2.03)and slope was 1.20(1.01 to 1.40). LOA and LPR are suitable techniques to compare 2 measurements and, because the levels are large and the slope does not encompass 1, suggest that the knee's PTE at 2.1 radlsec is unreliable.},
  file = {/Users/mladenjovanovic/Zotero/storage/9PKPAC9H/Mullineaux et al. - 1999 - Assessment of Bias in Comparing Measurements A Re.pdf},
  journal = {Measurement in Physical Education and Exercise Science},
  language = {en},
  number = {4}
}

@article{lubkeWhyWeShould2020,
  title = {Why {{We Should Teach Causal Inference}}: {{Examples}} in {{Linear Regression With Simulated Data}}},
  shorttitle = {Why {{We Should Teach Causal Inference}}},
  author = {L{\"u}bke, Karsten and Gehrke, Matthias and Horst, J{\"o}rg and Szepannek, Gero},
  year = {2020},
  month = may,
  pages = {1--7},
  issn = {1069-1898},
  doi = {10.1080/10691898.2020.1752859},
  abstract = {Basic knowledge of ideas of causal inference can help students to think beyond e data, i.e. to think more clearly about the data generating process. Especially for c (maybe big) observational data, qualitative assumptions are important for the conclusions drawn and interpretation of the quantitative results. Concepts of c causal inference can also help to overcome the mantra ``Correlation does not imply Causation''. To motivate and introduce causal inference in introductory Astatistics or data science courses, we use simulated data and simple linear regression to show the effects of confounding and when one should or should not adjust for covariables.},
  journal = {Journal of Statistics Education},
  language = {en}
}


@article{keoghSTRATOSGuidanceDocument2020,
  ids = {keoghSTRATOSGuidanceDocument2020a},
  title = {{{STRATOS}} Guidance Document on Measurement Error and Misclassification of Variables in Observational Epidemiology: {{Part}} 1-{{Basic}} Theory and Simple Methods of Adjustment},
  shorttitle = {{{STRATOS}} Guidance Document on Measurement Error and Misclassification of Variables in Observational Epidemiology},
  author = {Keogh, Ruth H. and Shaw, Pamela A. and Gustafson, Paul and Carroll, Raymond J. and Deffner, Veronika and Dodd, Kevin W. and K{\"u}chenhoff, Helmut and Tooze, Janet A. and Wallace, Michael P. and Kipnis, Victor and Freedman, Laurence S.},
  year = {2020},
  month = apr,
  issn = {02776715},
  doi = {10.1002/sim.8532},
  file = {/Users/mladenjovanovic/Zotero/storage/DM8EPG5P/Keogh et al. - 2020 - STRATOS guidance document on measurement error and.pdf;/Users/mladenjovanovic/Zotero/storage/RE8B5RQK/Keogh et al. - 2020 - STRATOS guidance document on measurement error and.pdf},
  journal = {Statistics in Medicine},
  language = {en}
}

@article{LedererSimex2006,
  title = {A Short Introduction to the {{SIMEX}} and {{MCSIMEX}}},
  author = {Lederer, Wolfgang and K{\"u}chenhoff, Helmut},
  year = {2006},
  month = jan,
  volume = {6},
  journal = {R News}
}

@article{shangMeasurementErrorAdjustment2012,
  title = {Measurement {{Error Adjustment Using}} the {{SIMEX Method}}: {{An Application}} to {{Student Growth Percentiles}}: {{{\emph{Measurement Error Adjustment Using}}}}{\emph{ the }}{{{\emph{SIMEX Method}}}}},
  shorttitle = {Measurement {{Error Adjustment Using}} the {{SIMEX Method}}},
  author = {Shang, Yi},
  year = {2012},
  month = dec,
  volume = {49},
  pages = {446--465},
  issn = {00220655},
  doi = {10.1111/j.1745-3984.2012.00186.x},
  file = {/Users/mladenjovanovic/Zotero/storage/ML3KS7D9/Shang - 2012 - Measurement Error Adjustment Using the SIMEX Metho.pdf},
  journal = {Journal of Educational Measurement},
  language = {en},
  number = {4}
}

@article{shawSTRATOSGuidanceDocument2020,
  ids = {shawSTRATOSGuidanceDocument2020a},
  title = {{{STRATOS}} Guidance Document on Measurement Error and Misclassification of Variables in Observational Epidemiology: {{Part}} 2-{{More}} Complex Methods of Adjustment and Advanced Topics},
  shorttitle = {{{STRATOS}} Guidance Document on Measurement Error and Misclassification of Variables in Observational Epidemiology},
  author = {Shaw, Pamela A. and Gustafson, Paul and Carroll, Raymond J. and Deffner, Veronika and Dodd, Kevin W. and Keogh, Ruth H. and Kipnis, Victor and Tooze, Janet A. and Wallace, Michael P. and K{\"u}chenhoff, Helmut and Freedman, Laurence S.},
  year = {2020},
  month = apr,
  issn = {02776715},
  doi = {10.1002/sim.8531},
  file = {/Users/mladenjovanovic/Zotero/storage/KJ3PXLLV/Shaw et al. - 2020 - STRATOS guidance document on measurement error and.pdf},
  journal = {Statistics in Medicine},
  language = {en}
}

@article{wallaceAnalysisImperfectWorld2020,
  ids = {wallaceAnalysisImperfectWorld2020a},
  title = {Analysis in an Imperfect World},
  author = {Wallace, Michael},
  year = {2020},
  month = feb,
  volume = {17},
  pages = {14--19},
  issn = {1740-9705, 1740-9713},
  doi = {10.1111/j.1740-9713.2020.01353.x},
  file = {/Users/mladenjovanovic/Zotero/storage/AKKZIFGW/Wallace - 2020 - Analysis in an imperfect world.pdf;/Users/mladenjovanovic/Zotero/storage/LSYW5BIB/Wallace - 2020 - Analysis in an imperfect world.pdf},
  journal = {Significance},
  language = {en},
  number = {1}
}


@misc{jovanovicExtendingClassicalTest2020,
  title = {Extending the {{Classical Test Theory}} with {{Circular Performance Model}}},
  author = {Jovanovi{\'c}, Mladen},
  year = {2020},
  month = jan,
  abstract = {In this video, I will go more into these details and also provide an extension of this model, which I termed Circular Performance Model (CPM). CPM, in my opinion, better represent performance phenomenology we experience as coaches and athletes.},
  chapter = {Non-Membership Content},
  file = {/Users/mladenjovanovic/Zotero/storage/UWS4PLYC/extending-the-classical-test-theory-with-circular-performance-model.html},
  journal = {Complementary Training},
  language = {en-US}
}


@article{dankelMethodStopAnalyzing2019,
  title = {A {{Method}} to {{Stop Analyzing Random Error}} and {{Start Analyzing Differential Responders}} to {{Exercise}}},
  author = {Dankel, Scott J. and Loenneke, Jeremy P.},
  year = {2019},
  month = jun,
  issn = {0112-1642, 1179-2035},
  doi = {10.1007/s40279-019-01147-0},
  abstract = {It is commonly stated that individuals respond differently to exercise even when the same exercise intervention is performed. This has led many researchers to conduct exercise interventions and subsequently categorize individuals into different responder categories to determine what causes individuals to respond differently. Some methods by which differential responders are categorized include percentile ranks, standard deviations from the mean, and cluster analyses. Notably, each of these methods will result in the presence of differential responders even in the absence of an exercise intervention, indicating that individuals may be categorized based on the presence of random error as opposed to true differences in the exercise response. Here we propose a method by which differential responders can be classified after accounting for the presence of random error that is quantified from a time-matched control group. Individuals who exceed random error from the mean response of the intervention group can be confidently labelled as high and low responders. Importantly, the number of differential responders will be proportional to the ratio of variance in the exercise and control groups. We provide easy-to-follow steps and examples to demonstrate how this technique can identify differential responders to exercise. We also detail the flaws in other classification methods by demonstrating the number of differential responders who would have been classified using the same data set. Our hope is that this method will help to avoid misclassifying individuals based on random error and, in turn, increase the replicability of differential responder studies.},
  file = {/Users/mladenjovanovic/Zotero/storage/YA8YH72R/Dankel and Loenneke - 2019 - A Method to Stop Analyzing Random Error and Start .pdf},
  journal = {Sports Medicine},
  language = {en}
}

@article{tenanStatisticalPropertiesDankelLoenneke,
  title = {On the {{Statistical Properties}} of the {{Dankel}}-{{Loenneke Method}}},
  author = {Tenan, Matthew and Vigotsky, Andrew David and Caldwell, Aaron R},
  doi = {10.31236/osf.io/8ndhg},
  abstract = {Dankel and Loenneke [1] recently presented a new approach to identifying subgroups in parallel group study designs. Here, we briefly discuss our statistical concerns with proposed approach. We reveal that the error rates of the Danke-Loenneke approach are much higher than the claimed 5\%, and that these error rates are dependent on numerous factors, including sample size, effect variance, and random error. The Dankel-Loenneke method has poor statistical properties; as such, we suggest that the method not be used and the manuscript constitutes an ``honest error'' per the Committee on Publication Ethics (COPE) guidelines.},
  file = {/Users/mladenjovanovic/Zotero/storage/34I9GDCZ/Tenan et al. - On the Statistical Properties of the Dankel-Loenne.pdf},
  language = {en}
}


@article{blandStatisticalMethodsAssessing1986,
  title = {Statistical Methods for Assessing Agreement between Two Methods of Clinical Measurement},
  author = {Bland, J. M. and Altman, D. G.},
  year = {1986},
  month = feb,
  volume = {1},
  pages = {307--310},
  issn = {0140-6736},
  abstract = {In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old. Such investigations are often analysed inappropriately, notably by using correlation coefficients. The use of correlation is misleading. An alternative approach, based on graphical techniques and simple calculations, is described, together with the relation between this analysis and the assessment of repeatability.},
  journal = {Lancet (London, England)},
  keywords = {Diagnosis,Humans,Peak Expiratory Flow Rate,Statistics as Topic},
  language = {eng},
  number = {8476},
  pmid = {2868172}
}

@article{giavarinaUnderstandingBlandAltman2015,
  title = {Understanding {{Bland Altman}} Analysis},
  author = {Giavarina, Davide},
  year = {2015},
  month = jun,
  volume = {25},
  pages = {141--151},
  issn = {1330-0962},
  doi = {10.11613/BM.2015.015},
  abstract = {In a contemporary clinical laboratory it is very common to have to assess the agreement between two quantitative methods of measurement. The correct statistical approach to assess this degree of agreement is not obvious. Correlation and regression studies are frequently proposed. However, correlation studies the relationship between one variable and another, not the differences, and it is not recommended as a method for assessing the comparability between methods.
In 1983 Altman and Bland (B\&A) proposed an alternative analysis, based on the quantification of the agreement between two quantitative measurements by studying the mean difference and constructing limits of agreement.
The B\&A plot analysis is a simple way to evaluate a bias between the mean differences, and to estimate an agreement interval, within which 95\% of the differences of the second method, compared to the first one, fall. Data can be analyzed both as unit differences plot and as percentage differences plot.
The B\&A plot method only defines the intervals of agreements, it does not say whether those limits are acceptable or not. Acceptable limits must be defined a priori, based on clinical necessity, biological considerations or other goals.
The aim of this article is to provide guidance on the use and interpretation of Bland Altman analysis in method comparison studies.},
  file = {/Users/mladenjovanovic/Zotero/storage/S5CRJVQA/Giavarina - 2015 - Understanding Bland Altman analysis.pdf},
  journal = {Biochemia Medica},
  number = {2},
  pmcid = {PMC4470095},
  pmid = {26110027}
}
